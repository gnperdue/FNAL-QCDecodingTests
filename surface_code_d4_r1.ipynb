{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the dependencies are handled in the other modules, but we import a few general ones here for use below and future expansion purposes.\n",
    "Notice that we are also modifying the matplotlib settings to work with LaTeX math-mode syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "from matplotlib import pyplot as plt\n",
    "from jupyter_plotter import plot_jupyter_figure\n",
    "import pymatching # Decoding\n",
    "from circuit_generators import *\n",
    "from sampling_functions import *\n",
    "import numpy as np\n",
    "\n",
    "# Also define the number of worker nodes here\n",
    "n_worker_nodes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUBIT_COORDS(1, 1) 1\n",
      "QUBIT_COORDS(2, 0) 2\n",
      "QUBIT_COORDS(3, 1) 3\n",
      "QUBIT_COORDS(5, 1) 5\n",
      "QUBIT_COORDS(6, 0) 6\n",
      "QUBIT_COORDS(7, 1) 7\n",
      "QUBIT_COORDS(1, 3) 10\n",
      "QUBIT_COORDS(2, 2) 11\n",
      "QUBIT_COORDS(3, 3) 12\n",
      "QUBIT_COORDS(4, 2) 13\n",
      "QUBIT_COORDS(5, 3) 14\n",
      "QUBIT_COORDS(6, 2) 15\n",
      "QUBIT_COORDS(7, 3) 16\n",
      "QUBIT_COORDS(0, 4) 18\n",
      "QUBIT_COORDS(1, 5) 19\n",
      "QUBIT_COORDS(2, 4) 20\n",
      "QUBIT_COORDS(3, 5) 21\n",
      "QUBIT_COORDS(4, 4) 22\n",
      "QUBIT_COORDS(5, 5) 23\n",
      "QUBIT_COORDS(6, 4) 24\n",
      "QUBIT_COORDS(7, 5) 25\n",
      "QUBIT_COORDS(8, 4) 26\n",
      "QUBIT_COORDS(1, 7) 28\n",
      "QUBIT_COORDS(2, 6) 29\n",
      "QUBIT_COORDS(3, 7) 30\n",
      "QUBIT_COORDS(4, 6) 31\n",
      "QUBIT_COORDS(5, 7) 32\n",
      "QUBIT_COORDS(6, 6) 33\n",
      "QUBIT_COORDS(7, 7) 34\n",
      "QUBIT_COORDS(2, 8) 38\n",
      "QUBIT_COORDS(6, 8) 42\n",
      "R 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "X_ERROR(0.01) 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "R 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "TICK\n",
      "DEPOLARIZE1(0.01) 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "H 2 6 13 20 24 31 38 42\n",
      "DEPOLARIZE1(0.01) 2 6 13 20 24 31 38 42\n",
      "TICK\n",
      "CX 2 3 20 21 13 14 31 32 6 7 24 25 19 18 12 11 30 29 23 22 16 15 34 33\n",
      "DEPOLARIZE2(0.01) 2 3 20 21 13 14 31 32 6 7 24 25 19 18 12 11 30 29 23 22 16 15 34 33\n",
      "TICK\n",
      "CX 2 1 20 19 13 12 31 30 6 5 24 23 10 18 3 11 21 29 14 22 7 15 25 33\n",
      "DEPOLARIZE2(0.01) 2 1 20 19 13 12 31 30 6 5 24 23 10 18 3 11 21 29 14 22 7 15 25 33\n",
      "TICK\n",
      "CX 20 12 38 30 13 5 31 23 24 16 42 34 10 11 28 29 21 22 14 15 32 33 25 26\n",
      "DEPOLARIZE2(0.01) 20 12 38 30 13 5 31 23 24 16 42 34 10 11 28 29 21 22 14 15 32 33 25 26\n",
      "TICK\n",
      "CX 20 10 38 28 13 3 31 21 24 14 42 32 1 11 19 29 12 22 5 15 23 33 16 26\n",
      "DEPOLARIZE2(0.01) 20 10 38 28 13 3 31 21 24 14 42 32 1 11 19 29 12 22 5 15 23 33 16 26\n",
      "TICK\n",
      "H 2 6 13 20 24 31 38 42\n",
      "DEPOLARIZE1(0.01) 2 6 13 20 24 31 38 42\n",
      "TICK\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "MR 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "DETECTOR(0, 4, 0) rec[-10]\n",
      "DETECTOR(2, 2, 0) rec[-13]\n",
      "DETECTOR(2, 6, 0) rec[-5]\n",
      "DETECTOR(4, 4, 0) rec[-8]\n",
      "DETECTOR(6, 2, 0) rec[-11]\n",
      "DETECTOR(6, 6, 0) rec[-3]\n",
      "DETECTOR(8, 4, 0) rec[-6]\n",
      "X_ERROR(0.01) 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "M 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "DETECTOR(0, 4, 1) rec[-8] rec[-12] rec[-26]\n",
      "DETECTOR(2, 2, 1) rec[-11] rec[-12] rec[-15] rec[-16] rec[-29]\n",
      "DETECTOR(2, 6, 1) rec[-3] rec[-4] rec[-7] rec[-8] rec[-21]\n",
      "DETECTOR(4, 4, 1) rec[-6] rec[-7] rec[-10] rec[-11] rec[-24]\n",
      "DETECTOR(6, 2, 1) rec[-9] rec[-10] rec[-13] rec[-14] rec[-27]\n",
      "DETECTOR(6, 6, 1) rec[-1] rec[-2] rec[-5] rec[-6] rec[-19]\n",
      "DETECTOR(8, 4, 1) rec[-5] rec[-9] rec[-22]\n",
      "OBSERVABLE_INCLUDE(0) rec[-13] rec[-14] rec[-15] rec[-16]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 6000000\n",
    "decoders = ['pymatching']\n",
    "test_circuit = get_builtin_circuit(\n",
    "  \"surface_code:rotated_memory_z\",\n",
    "  distance=4,\n",
    "  rounds=1,\n",
    "  before_round_data_depolarization = 0.01,\n",
    "  after_reset_flip_probability = 0.01,\n",
    "  after_clifford_depolarization = 0.01,\n",
    "  before_measure_flip_probability = 0.01\n",
    ")\n",
    "m_sampler = test_circuit.compile_sampler(seed=12345)\n",
    "d_sampler = test_circuit.compile_detector_sampler(seed=12345)\n",
    "converter = test_circuit.compile_m2d_converter()\n",
    "\n",
    "measurements = m_sampler.sample(n_samples, bit_packed=False)\n",
    "det_evts, flips = converter.convert(measurements=measurements, separate_observables=True, bit_packed=False)\n",
    "measurements = measurements.astype(np.int16)\n",
    "det_evts = det_evts.astype(np.int16)\n",
    "flips = flips.astype(np.int16)\n",
    "print(test_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1]\n",
      " [1 1 0 0]\n",
      " [0 1 1 1]\n",
      " ...\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "exclude_indices = np.array([-13, -14, -15, -16], dtype=np.int16)\n",
    "n_measurements = measurements.shape[1]\n",
    "exclude_indices = exclude_indices + n_measurements\n",
    "exclude_indices_obs = np.arange(0, measurements.shape[1], 1, dtype=np.int16)\n",
    "exclude_indices_obs = np.delete(exclude_indices_obs, exclude_indices)\n",
    "\n",
    "det_bits = measurements\n",
    "det_bits = np.delete(det_bits, exclude_indices, axis=1)\n",
    "obs_bits = measurements\n",
    "obs_bits = np.delete(obs_bits, exclude_indices_obs, axis=1)\n",
    "print(obs_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_error_model = test_circuit.detector_error_model(decompose_errors=True)\n",
    "pymatcher = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "predictions_pym = pymatcher.decode_batch(det_evts, bit_packed_predictions=False, bit_packed_shots=False)\n",
    "predictions_pym = predictions_pym.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1]\n",
      " [1 1 0 0]\n",
      " [0 1 1 1]\n",
      " ...\n",
      " [1 1 1 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the input for training\n",
    "incorrect_matches = (predictions_pym != flips)\n",
    "class_bits = obs_bits\n",
    "class_bits_wpym = np.concatenate((obs_bits, incorrect_matches), axis=1)\n",
    "feature_bits = np.concatenate((det_bits, det_evts), axis=1)\n",
    "feature_bits_wpym = np.concatenate((det_bits, det_evts, predictions_pym), axis=1)\n",
    "print(class_bits)\n",
    "\n",
    "def bit_pack_bits(ev_bits):\n",
    "  res: np.int16 = 0\n",
    "  for i in range(ev_bits.shape[0]):\n",
    "    res = res | (np.int16(ev_bits[i]) << i)\n",
    "  return res\n",
    "\n",
    "class_bits_packed = np.zeros(class_bits.shape[0], dtype=np.int16)\n",
    "class_bits_wpym_packed = np.zeros(class_bits.shape[0], dtype=np.int16)\n",
    "for iev in range(class_bits.shape[0]):\n",
    "  class_bits_packed[iev] = bit_pack_bits(class_bits[iev])\n",
    "  class_bits_wpym_packed[iev] = bit_pack_bits(class_bits_wpym[iev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utilities_tf import *\n",
    "test_fraction = 5./6.\n",
    "feature_bits_train, feature_bits_test, class_bits_train, class_bits_test = split_data(features = feature_bits, labels = class_bits_packed, test_size=test_fraction)\n",
    "feature_bits_train_wpym, feature_bits_test_wpym, class_bits_train_wpym, class_bits_test_wpym = split_data(features = feature_bits_wpym, labels = class_bits_wpym_packed, test_size=test_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build models with 2 dense layers with an equal number `nn` of nodes:\n",
    "- `nn` ranges from 40 to 120 in steps of 10\n",
    "- One set of models (`models_wpym`) use only the bits for (syndrome measurements) (x) (detection events) (same inherent information but apparently helps with training: https://arxiv.org/abs/2310.05900) as features. The labels are the (bitmap of d(=4) measurements) for which we are eventually looking for an even or odd XOR result.\n",
    "- In the other set (`models_wpym`), we use bit the bits for (syndrome measurements) (x) (detection events) (x) (one extra bit for the flag from pyMatching that predicts a flip in the XOR result). The labels are the (bitmap of d(=4) measurements) (x) (one bit to flag an incorrect pyMatching prediction).\n",
    "\n",
    "In this way, any measurement of observable significance ends up being a label for the NN to predict. Any measurement that directly or indirectly relates to the set of syndrome measurements ends up in input features.\n",
    "\n",
    "Things we could also do is to adjust the layer 1 : layer 2 ratio of the number of nodes, or change the number of layers altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense (QDense)            (None, 40)                1680      \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 40)                1640      \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 16)                656       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3976 (15.53 KB)\n",
      "Trainable params: 3976 (15.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_3 (QDense)          (None, 40)                1720      \n",
      "                                                                 \n",
      " q_dense_4 (QDense)          (None, 40)                1640      \n",
      "                                                                 \n",
      " q_dense_5 (QDense)          (None, 32)                1312      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4672 (18.25 KB)\n",
      "Trainable params: 4672 (18.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_6 (QDense)          (None, 80)                3360      \n",
      "                                                                 \n",
      " q_dense_7 (QDense)          (None, 80)                6480      \n",
      "                                                                 \n",
      " q_dense_8 (QDense)          (None, 16)                1296      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11136 (43.50 KB)\n",
      "Trainable params: 11136 (43.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_9 (QDense)          (None, 80)                3440      \n",
      "                                                                 \n",
      " q_dense_10 (QDense)         (None, 80)                6480      \n",
      "                                                                 \n",
      " q_dense_11 (QDense)         (None, 32)                2592      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12512 (48.88 KB)\n",
      "Trainable params: 12512 (48.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_12 (QDense)         (None, 120)               5040      \n",
      "                                                                 \n",
      " q_dense_13 (QDense)         (None, 120)               14520     \n",
      "                                                                 \n",
      " q_dense_14 (QDense)         (None, 16)                1936      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21496 (83.97 KB)\n",
      "Trainable params: 21496 (83.97 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_15 (QDense)         (None, 120)               5160      \n",
      "                                                                 \n",
      " q_dense_16 (QDense)         (None, 120)               14520     \n",
      "                                                                 \n",
      " q_dense_17 (QDense)         (None, 32)                3872      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23552 (92.00 KB)\n",
      "Trainable params: 23552 (92.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_18 (QDense)         (None, 160)               6720      \n",
      "                                                                 \n",
      " q_dense_19 (QDense)         (None, 160)               25760     \n",
      "                                                                 \n",
      " q_dense_20 (QDense)         (None, 16)                2576      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35056 (136.94 KB)\n",
      "Trainable params: 35056 (136.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_21 (QDense)         (None, 160)               6880      \n",
      "                                                                 \n",
      " q_dense_22 (QDense)         (None, 160)               25760     \n",
      "                                                                 \n",
      " q_dense_23 (QDense)         (None, 32)                5152      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37792 (147.62 KB)\n",
      "Trainable params: 37792 (147.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_24 (QDense)         (None, 200)               8400      \n",
      "                                                                 \n",
      " q_dense_25 (QDense)         (None, 200)               40200     \n",
      "                                                                 \n",
      " q_dense_26 (QDense)         (None, 16)                3216      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51816 (202.41 KB)\n",
      "Trainable params: 51816 (202.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " q_dense_27 (QDense)         (None, 200)               8600      \n",
      "                                                                 \n",
      " q_dense_28 (QDense)         (None, 200)               40200     \n",
      "                                                                 \n",
      " q_dense_29 (QDense)         (None, 32)                6432      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55232 (215.75 KB)\n",
      "Trainable params: 55232 (215.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nnodes = [ nn for nn in range(40, 240, 40)]\n",
    "nlayers = 2\n",
    "models_nnonly = []\n",
    "models_wpym = []\n",
    "for nn in nnodes:\n",
    "  node_arg = [ (nn, 8) for _ in range(nlayers) ]\n",
    "\n",
    "  models_nnonly.append(\n",
    "    build_sequential_qdense_model(\n",
    "      feature_bits.shape[1], pow(2, class_bits.shape[1]),\n",
    "      node_arg,\n",
    "      loss_fcn = \"sparse_categorical_crossentropy\",\n",
    "      output_activation = \"softmax\"\n",
    "    )\n",
    "  )\n",
    "  models_wpym.append(\n",
    "    build_sequential_qdense_model(\n",
    "      feature_bits_wpym.shape[1], pow(2, class_bits_wpym.shape[1]),\n",
    "      node_arg,\n",
    "      loss_fcn = \"sparse_categorical_crossentropy\",\n",
    "      output_activation = \"softmax\"\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models with no pyMatching input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with n_dense = (40, 40) layers:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 3s 28ms/step - loss: 2.6481 - accuracy: 0.0908 - val_loss: 2.4769 - val_accuracy: 0.1226\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 2.4259 - accuracy: 0.1379 - val_loss: 2.3510 - val_accuracy: 0.1595\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 2.2024 - accuracy: 0.1842 - val_loss: 2.0234 - val_accuracy: 0.1987\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 1.9168 - accuracy: 0.2040 - val_loss: 1.8467 - val_accuracy: 0.2087\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 1.8045 - accuracy: 0.2114 - val_loss: 1.7658 - val_accuracy: 0.2129\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.7301 - accuracy: 0.2174 - val_loss: 1.6951 - val_accuracy: 0.2211\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.6593 - accuracy: 0.2263 - val_loss: 1.6233 - val_accuracy: 0.2321\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.5849 - accuracy: 0.2356 - val_loss: 1.5508 - val_accuracy: 0.2388\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.5251 - accuracy: 0.2412 - val_loss: 1.5056 - val_accuracy: 0.2438\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4888 - accuracy: 0.2446 - val_loss: 1.4758 - val_accuracy: 0.2469\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4627 - accuracy: 0.2469 - val_loss: 1.4536 - val_accuracy: 0.2481\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.4437 - accuracy: 0.2490 - val_loss: 1.4376 - val_accuracy: 0.2491\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4302 - accuracy: 0.2501 - val_loss: 1.4259 - val_accuracy: 0.2491\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4205 - accuracy: 0.2500 - val_loss: 1.4176 - val_accuracy: 0.2503\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.4135 - accuracy: 0.2513 - val_loss: 1.4115 - val_accuracy: 0.2505\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4083 - accuracy: 0.2506 - val_loss: 1.4073 - val_accuracy: 0.2497\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.4045 - accuracy: 0.2506 - val_loss: 1.4037 - val_accuracy: 0.2497\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.4016 - accuracy: 0.2512 - val_loss: 1.4010 - val_accuracy: 0.2518\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.3994 - accuracy: 0.2515 - val_loss: 1.3989 - val_accuracy: 0.2521\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.3976 - accuracy: 0.2514 - val_loss: 1.3975 - val_accuracy: 0.2501\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.3962 - accuracy: 0.2519 - val_loss: 1.3961 - val_accuracy: 0.2512\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 2s 21ms/step - loss: 1.3950 - accuracy: 0.2519 - val_loss: 1.3951 - val_accuracy: 0.2496\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.3940 - accuracy: 0.2527 - val_loss: 1.3940 - val_accuracy: 0.2508\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 2s 20ms/step - loss: 1.3931 - accuracy: 0.2523 - val_loss: 1.3933 - val_accuracy: 0.2511\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.3925 - accuracy: 0.2533 - val_loss: 1.3927 - val_accuracy: 0.2500\n",
      "Training data loss: 1.392120, accuracy: 0.252875\n",
      "Test data loss: 1.392607, accuracy: 0.250234\n",
      "Training the model with n_dense = (80, 80) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 2.4673 - accuracy: 0.1390 - val_loss: 2.2847 - val_accuracy: 0.1811\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 2.0545 - accuracy: 0.1973 - val_loss: 1.8921 - val_accuracy: 0.2028\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 1.8168 - accuracy: 0.2114 - val_loss: 1.7516 - val_accuracy: 0.2177\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 1.6908 - accuracy: 0.2255 - val_loss: 1.6314 - val_accuracy: 0.2324\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 1.5739 - accuracy: 0.2393 - val_loss: 1.5250 - val_accuracy: 0.2423\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 1.4881 - accuracy: 0.2459 - val_loss: 1.4615 - val_accuracy: 0.2462\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 1.4419 - accuracy: 0.2500 - val_loss: 1.4293 - val_accuracy: 0.2489\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 1.4189 - accuracy: 0.2515 - val_loss: 1.4129 - val_accuracy: 0.2500\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.4070 - accuracy: 0.2529 - val_loss: 1.4042 - val_accuracy: 0.2492\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 1.4004 - accuracy: 0.2531 - val_loss: 1.3994 - val_accuracy: 0.2485\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 1.3966 - accuracy: 0.2532 - val_loss: 1.3962 - val_accuracy: 0.2493\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.3941 - accuracy: 0.2547 - val_loss: 1.3944 - val_accuracy: 0.2483\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 1.3925 - accuracy: 0.2547 - val_loss: 1.3929 - val_accuracy: 0.2498\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.3913 - accuracy: 0.2550 - val_loss: 1.3919 - val_accuracy: 0.2501\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.3904 - accuracy: 0.2559 - val_loss: 1.3914 - val_accuracy: 0.2503\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 1.3898 - accuracy: 0.2561 - val_loss: 1.3909 - val_accuracy: 0.2504\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 1.3892 - accuracy: 0.2559 - val_loss: 1.3902 - val_accuracy: 0.2494\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 3s 42ms/step - loss: 1.3887 - accuracy: 0.2566 - val_loss: 1.3899 - val_accuracy: 0.2495\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 3s 39ms/step - loss: 1.3884 - accuracy: 0.2570 - val_loss: 1.3898 - val_accuracy: 0.2500\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.3881 - accuracy: 0.2573 - val_loss: 1.3895 - val_accuracy: 0.2490\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 3s 43ms/step - loss: 1.3878 - accuracy: 0.2585 - val_loss: 1.3892 - val_accuracy: 0.2493\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.3875 - accuracy: 0.2591 - val_loss: 1.3890 - val_accuracy: 0.2496\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.3873 - accuracy: 0.2589 - val_loss: 1.3889 - val_accuracy: 0.2493\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 3s 41ms/step - loss: 1.3871 - accuracy: 0.2597 - val_loss: 1.3887 - val_accuracy: 0.2498\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 1.3870 - accuracy: 0.2596 - val_loss: 1.3886 - val_accuracy: 0.2492\n",
      "Training data loss: 1.386926, accuracy: 0.259428\n",
      "Test data loss: 1.388695, accuracy: 0.249862\n",
      "Training the model with n_dense = (120, 120) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 6s 64ms/step - loss: 2.4235 - accuracy: 0.1537 - val_loss: 2.1718 - val_accuracy: 0.1948\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.9722 - accuracy: 0.2026 - val_loss: 1.8557 - val_accuracy: 0.2065\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 1.7839 - accuracy: 0.2140 - val_loss: 1.7089 - val_accuracy: 0.2235\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.6398 - accuracy: 0.2342 - val_loss: 1.5784 - val_accuracy: 0.2408\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.5311 - accuracy: 0.2441 - val_loss: 1.4945 - val_accuracy: 0.2457\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 1.4666 - accuracy: 0.2503 - val_loss: 1.4462 - val_accuracy: 0.2485\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 1.4287 - accuracy: 0.2527 - val_loss: 1.4179 - val_accuracy: 0.2502\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 1.4095 - accuracy: 0.2540 - val_loss: 1.4054 - val_accuracy: 0.2514\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 5s 64ms/step - loss: 1.4008 - accuracy: 0.2552 - val_loss: 1.3999 - val_accuracy: 0.2500\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3965 - accuracy: 0.2555 - val_loss: 1.3967 - val_accuracy: 0.2514\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3937 - accuracy: 0.2574 - val_loss: 1.3946 - val_accuracy: 0.2508\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 5s 66ms/step - loss: 1.3921 - accuracy: 0.2568 - val_loss: 1.3933 - val_accuracy: 0.2508\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3909 - accuracy: 0.2586 - val_loss: 1.3924 - val_accuracy: 0.2499\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 5s 68ms/step - loss: 1.3900 - accuracy: 0.2587 - val_loss: 1.3912 - val_accuracy: 0.2521\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3891 - accuracy: 0.2593 - val_loss: 1.3908 - val_accuracy: 0.2518\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3886 - accuracy: 0.2600 - val_loss: 1.3905 - val_accuracy: 0.2507\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3881 - accuracy: 0.2607 - val_loss: 1.3902 - val_accuracy: 0.2515\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3877 - accuracy: 0.2612 - val_loss: 1.3900 - val_accuracy: 0.2506\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3873 - accuracy: 0.2628 - val_loss: 1.3898 - val_accuracy: 0.2497\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3870 - accuracy: 0.2626 - val_loss: 1.3897 - val_accuracy: 0.2506\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3867 - accuracy: 0.2633 - val_loss: 1.3898 - val_accuracy: 0.2514\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3865 - accuracy: 0.2633 - val_loss: 1.3893 - val_accuracy: 0.2510\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3863 - accuracy: 0.2639 - val_loss: 1.3895 - val_accuracy: 0.2518\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.3861 - accuracy: 0.2649 - val_loss: 1.3891 - val_accuracy: 0.2496\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 1.3859 - accuracy: 0.2656 - val_loss: 1.3895 - val_accuracy: 0.2499\n",
      "Training data loss: 1.386378, accuracy: 0.262422\n",
      "Test data loss: 1.389523, accuracy: 0.250009\n",
      "Training the model with n_dense = (160, 160) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 8s 88ms/step - loss: 2.3756 - accuracy: 0.1574 - val_loss: 2.0685 - val_accuracy: 0.2011\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 7s 84ms/step - loss: 1.8971 - accuracy: 0.2067 - val_loss: 1.7868 - val_accuracy: 0.2136\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 1.7034 - accuracy: 0.2253 - val_loss: 1.6256 - val_accuracy: 0.2335\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 7s 86ms/step - loss: 1.5662 - accuracy: 0.2412 - val_loss: 1.5200 - val_accuracy: 0.2424\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 1.4891 - accuracy: 0.2476 - val_loss: 1.4671 - val_accuracy: 0.2456\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 1.4496 - accuracy: 0.2518 - val_loss: 1.4384 - val_accuracy: 0.2468\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 7s 93ms/step - loss: 1.4275 - accuracy: 0.2541 - val_loss: 1.4226 - val_accuracy: 0.2469\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 7s 90ms/step - loss: 1.4151 - accuracy: 0.2553 - val_loss: 1.4124 - val_accuracy: 0.2482\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 1.4074 - accuracy: 0.2566 - val_loss: 1.4067 - val_accuracy: 0.2504\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 1.4023 - accuracy: 0.2576 - val_loss: 1.4027 - val_accuracy: 0.2489\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 7s 88ms/step - loss: 1.3986 - accuracy: 0.2591 - val_loss: 1.3995 - val_accuracy: 0.2502\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 7s 87ms/step - loss: 1.3960 - accuracy: 0.2593 - val_loss: 1.3973 - val_accuracy: 0.2494\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 7s 88ms/step - loss: 1.3937 - accuracy: 0.2596 - val_loss: 1.3953 - val_accuracy: 0.2505\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 1.3921 - accuracy: 0.2611 - val_loss: 1.3941 - val_accuracy: 0.2505\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 1.3908 - accuracy: 0.2619 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 7s 86ms/step - loss: 1.3899 - accuracy: 0.2620 - val_loss: 1.3924 - val_accuracy: 0.2505\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 1.3888 - accuracy: 0.2631 - val_loss: 1.3916 - val_accuracy: 0.2499\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 7s 87ms/step - loss: 1.3882 - accuracy: 0.2639 - val_loss: 1.3919 - val_accuracy: 0.2510\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 7s 93ms/step - loss: 1.3877 - accuracy: 0.2649 - val_loss: 1.3908 - val_accuracy: 0.2505\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 1.3871 - accuracy: 0.2664 - val_loss: 1.3906 - val_accuracy: 0.2516\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 7s 90ms/step - loss: 1.3868 - accuracy: 0.2667 - val_loss: 1.3903 - val_accuracy: 0.2505\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 7s 91ms/step - loss: 1.3864 - accuracy: 0.2664 - val_loss: 1.3903 - val_accuracy: 0.2502\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 1.3860 - accuracy: 0.2682 - val_loss: 1.3902 - val_accuracy: 0.2501\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 7s 93ms/step - loss: 1.3858 - accuracy: 0.2679 - val_loss: 1.3904 - val_accuracy: 0.2498\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 7s 92ms/step - loss: 1.3855 - accuracy: 0.2689 - val_loss: 1.3901 - val_accuracy: 0.2505\n",
      "Training data loss: 1.385598, accuracy: 0.268423\n",
      "Test data loss: 1.390105, accuracy: 0.250095\n",
      "Training the model with n_dense = (200, 200) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 10s 110ms/step - loss: 2.2853 - accuracy: 0.1748 - val_loss: 1.9650 - val_accuracy: 0.2022\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 1.8267 - accuracy: 0.2131 - val_loss: 1.6979 - val_accuracy: 0.2265\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.6078 - accuracy: 0.2390 - val_loss: 1.5426 - val_accuracy: 0.2402\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 1.5031 - accuracy: 0.2478 - val_loss: 1.4763 - val_accuracy: 0.2440\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 1.4572 - accuracy: 0.2515 - val_loss: 1.4452 - val_accuracy: 0.2484\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 1.4344 - accuracy: 0.2533 - val_loss: 1.4286 - val_accuracy: 0.2485\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.4213 - accuracy: 0.2559 - val_loss: 1.4186 - val_accuracy: 0.2490\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.4129 - accuracy: 0.2571 - val_loss: 1.4121 - val_accuracy: 0.2489\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 9s 110ms/step - loss: 1.4072 - accuracy: 0.2584 - val_loss: 1.4075 - val_accuracy: 0.2485\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.4033 - accuracy: 0.2593 - val_loss: 1.4042 - val_accuracy: 0.2496\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 1.4003 - accuracy: 0.2603 - val_loss: 1.4019 - val_accuracy: 0.2490\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.3979 - accuracy: 0.2610 - val_loss: 1.4001 - val_accuracy: 0.2486\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.3963 - accuracy: 0.2626 - val_loss: 1.3989 - val_accuracy: 0.2474\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 8s 106ms/step - loss: 1.3947 - accuracy: 0.2636 - val_loss: 1.3975 - val_accuracy: 0.2489\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.3935 - accuracy: 0.2649 - val_loss: 1.3967 - val_accuracy: 0.2488\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 1.3926 - accuracy: 0.2649 - val_loss: 1.3960 - val_accuracy: 0.2502\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.3917 - accuracy: 0.2661 - val_loss: 1.3957 - val_accuracy: 0.2489\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 9s 109ms/step - loss: 1.3908 - accuracy: 0.2673 - val_loss: 1.3950 - val_accuracy: 0.2493\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3903 - accuracy: 0.2682 - val_loss: 1.3946 - val_accuracy: 0.2490\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 9s 115ms/step - loss: 1.3895 - accuracy: 0.2692 - val_loss: 1.3943 - val_accuracy: 0.2506\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 1.3890 - accuracy: 0.2688 - val_loss: 1.3940 - val_accuracy: 0.2495\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 8s 103ms/step - loss: 1.3884 - accuracy: 0.2713 - val_loss: 1.3941 - val_accuracy: 0.2496\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 8s 105ms/step - loss: 1.3879 - accuracy: 0.2714 - val_loss: 1.3940 - val_accuracy: 0.2502\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.3874 - accuracy: 0.2723 - val_loss: 1.3939 - val_accuracy: 0.2487\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.3870 - accuracy: 0.2731 - val_loss: 1.3933 - val_accuracy: 0.2498\n",
      "Training data loss: 1.387300, accuracy: 0.271460\n",
      "Test data loss: 1.393336, accuracy: 0.249987\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "val_split = 0.2\n",
    "n_epochs = 25\n",
    "for model in models_nnonly:\n",
    "  print(f\"Training the model with n_dense = ({nnodes[i]}, {nnodes[i]}) layers:\")\n",
    "  history = model.fit(feature_bits_train, class_bits_train, epochs=n_epochs, batch_size=10000, validation_split=val_split)\n",
    "  # In this test case, looking at the values of accuracies is not informative,\n",
    "  # but comparing their values between training and testing data sets still tells us about overtraining.\n",
    "  test_model(model, feature_bits_train, class_bits_train, feature_bits_test, class_bits_test)\n",
    "  i=i+1\n",
    "i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to translate the bits back to the XOR result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_XOR_prediction(bitmap):\n",
    "  \"\"\"\n",
    "  Assumes that the first four bits correspond to the observable bits that construct the XOR.\n",
    "  \"\"\"\n",
    "  bitsum=0\n",
    "  for i in range(4):\n",
    "    bitsum = bitsum + ((bitmap>>i)&1)\n",
    "  return bitsum%2\n",
    "\n",
    "get_XOR_prediction(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the predictions for `models_nnonly`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 20ms/step\n",
      "500/500 [==============================] - 7s 15ms/step\n",
      "Number of wrong training bitmap predictions: 747125 / 1000000\n",
      "Number of wrong test bitmap predictions: 3748828 / 5000000\n",
      "Number of wrong training XOR predictions: 22 / 1000000\n",
      "Number of wrong test XOR predictions: 135 / 5000000\n",
      "100/100 [==============================] - 4s 32ms/step\n",
      "500/500 [==============================] - 16s 33ms/step\n",
      "Number of wrong training bitmap predictions: 740572 / 1000000\n",
      "Number of wrong test bitmap predictions: 3750690 / 5000000\n",
      "Number of wrong training XOR predictions: 0 / 1000000\n",
      "Number of wrong test XOR predictions: 2 / 5000000\n",
      "100/100 [==============================] - 6s 57ms/step\n",
      "500/500 [==============================] - 25s 50ms/step\n",
      "Number of wrong training bitmap predictions: 737578 / 1000000\n",
      "Number of wrong test bitmap predictions: 3749956 / 5000000\n",
      "Number of wrong training XOR predictions: 0 / 1000000\n",
      "Number of wrong test XOR predictions: 1 / 5000000\n",
      "100/100 [==============================] - 7s 67ms/step\n",
      "500/500 [==============================] - 34s 67ms/step\n",
      "Number of wrong training bitmap predictions: 731577 / 1000000\n",
      "Number of wrong test bitmap predictions: 3749524 / 5000000\n",
      "Number of wrong training XOR predictions: 0 / 1000000\n",
      "Number of wrong test XOR predictions: 2 / 5000000\n",
      "100/100 [==============================] - 8s 76ms/step\n",
      "500/500 [==============================] - 38s 77ms/step\n",
      "Number of wrong training bitmap predictions: 728540 / 1000000\n",
      "Number of wrong test bitmap predictions: 3750064 / 5000000\n",
      "Number of wrong training XOR predictions: 5 / 1000000\n",
      "Number of wrong test XOR predictions: 40 / 5000000\n"
     ]
    }
   ],
   "source": [
    "# Keep track of the number of wrong bitmap predictions\n",
    "n_wrong_class_nnonly_train = np.zeros(len(models_nnonly), dtype=np.int32)\n",
    "n_wrong_class_nnonly_test = np.zeros(len(models_nnonly), dtype=np.int32)\n",
    "# Keep track of the number of actual XOR flip predictions\n",
    "n_wrong_XOR_nnonly_train = np.zeros(len(models_nnonly), dtype=np.int32)\n",
    "n_wrong_XOR_nnonly_test = np.zeros(len(models_nnonly), dtype=np.int32)\n",
    "\n",
    "imodel = 0\n",
    "for model in models_nnonly:\n",
    "  tmp = model.predict(feature_bits_train, batch_size=10000)\n",
    "  for i in range(tmp.shape[0]):\n",
    "    jp = 0\n",
    "    vjp = 0.\n",
    "    for j in range(tmp.shape[1]):\n",
    "      if tmp[i][j]>vjp:\n",
    "        vjp = tmp[i][j]\n",
    "        jp = j\n",
    "    if class_bits_train[i] != jp:\n",
    "      n_wrong_class_nnonly_train[imodel] = n_wrong_class_nnonly_train[imodel] + 1\n",
    "    has_flip_truth = get_XOR_prediction(class_bits_train[i])\n",
    "    has_flip_pred = get_XOR_prediction(jp)\n",
    "    if has_flip_pred != has_flip_truth:\n",
    "      n_wrong_XOR_nnonly_train[imodel] = n_wrong_XOR_nnonly_train[imodel] + 1\n",
    "    \n",
    "  tmp = model.predict(feature_bits_test, batch_size=10000)\n",
    "  for i in range(tmp.shape[0]):\n",
    "    jp = 0\n",
    "    vjp = 0.\n",
    "    for j in range(tmp.shape[1]):\n",
    "      if tmp[i][j]>vjp:\n",
    "        vjp = tmp[i][j]\n",
    "        jp = j\n",
    "    if class_bits_test[i] != jp:\n",
    "      n_wrong_class_nnonly_test[imodel] = n_wrong_class_nnonly_test[imodel] + 1\n",
    "    has_flip_truth = get_XOR_prediction(class_bits_test[i])\n",
    "    has_flip_pred = get_XOR_prediction(jp)\n",
    "    if has_flip_pred != has_flip_truth:\n",
    "      n_wrong_XOR_nnonly_test[imodel] = n_wrong_XOR_nnonly_test[imodel] + 1\n",
    "\n",
    "  print(f\"Number of wrong training bitmap predictions: {n_wrong_class_nnonly_train[imodel]} / {feature_bits_train.shape[0]}\")\n",
    "  print(f\"Number of wrong test bitmap predictions: {n_wrong_class_nnonly_test[imodel]} / {feature_bits_test.shape[0]}\")\n",
    "  print(f\"Number of wrong training XOR predictions: {n_wrong_XOR_nnonly_train[imodel]} / {feature_bits_train.shape[0]}\")\n",
    "  print(f\"Number of wrong test XOR predictions: {n_wrong_XOR_nnonly_test[imodel]} / {feature_bits_test.shape[0]}\")\n",
    "  imodel = imodel + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the models with PyMatching input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with n_dense = (40, 40) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 5s 38ms/step - loss: 3.0215 - accuracy: 0.0948 - val_loss: 2.5751 - val_accuracy: 0.1268\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 2.4374 - accuracy: 0.1408 - val_loss: 2.2987 - val_accuracy: 0.1633\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 2.1554 - accuracy: 0.1917 - val_loss: 2.0107 - val_accuracy: 0.2131\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 1.8824 - accuracy: 0.2192 - val_loss: 1.7793 - val_accuracy: 0.2240\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 1.7181 - accuracy: 0.2277 - val_loss: 1.6755 - val_accuracy: 0.2300\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 1.6441 - accuracy: 0.2342 - val_loss: 1.6184 - val_accuracy: 0.2359\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.5909 - accuracy: 0.2399 - val_loss: 1.5681 - val_accuracy: 0.2396\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 1.5493 - accuracy: 0.2423 - val_loss: 1.5365 - val_accuracy: 0.2408\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.5247 - accuracy: 0.2441 - val_loss: 1.5171 - val_accuracy: 0.2422\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 1.5081 - accuracy: 0.2443 - val_loss: 1.5027 - val_accuracy: 0.2436\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 2s 25ms/step - loss: 1.4953 - accuracy: 0.2455 - val_loss: 1.4911 - val_accuracy: 0.2444\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 1.4845 - accuracy: 0.2453 - val_loss: 1.4810 - val_accuracy: 0.2443\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 3s 35ms/step - loss: 1.4750 - accuracy: 0.2459 - val_loss: 1.4719 - val_accuracy: 0.2442\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.4664 - accuracy: 0.2457 - val_loss: 1.4633 - val_accuracy: 0.2459\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 1.4582 - accuracy: 0.2460 - val_loss: 1.4556 - val_accuracy: 0.2446\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 1.4505 - accuracy: 0.2463 - val_loss: 1.4479 - val_accuracy: 0.2462\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.4433 - accuracy: 0.2479 - val_loss: 1.4409 - val_accuracy: 0.2479\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 1.4365 - accuracy: 0.2482 - val_loss: 1.4344 - val_accuracy: 0.2477\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 1.4303 - accuracy: 0.2496 - val_loss: 1.4284 - val_accuracy: 0.2479\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 1.4246 - accuracy: 0.2493 - val_loss: 1.4229 - val_accuracy: 0.2483\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 1.4195 - accuracy: 0.2503 - val_loss: 1.4181 - val_accuracy: 0.2490\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 1.4149 - accuracy: 0.2503 - val_loss: 1.4137 - val_accuracy: 0.2480\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 1.4109 - accuracy: 0.2511 - val_loss: 1.4099 - val_accuracy: 0.2494\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 2s 23ms/step - loss: 1.4073 - accuracy: 0.2516 - val_loss: 1.4066 - val_accuracy: 0.2486\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 2s 22ms/step - loss: 1.4043 - accuracy: 0.2512 - val_loss: 1.4036 - val_accuracy: 0.2494\n",
      "Training data loss: 1.402869, accuracy: 0.252101\n",
      "Test data loss: 1.403332, accuracy: 0.249604\n",
      "Training the model with n_dense = (80, 80) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 7s 75ms/step - loss: 2.7769 - accuracy: 0.1177 - val_loss: 2.4030 - val_accuracy: 0.1612\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 2.1132 - accuracy: 0.1957 - val_loss: 1.8634 - val_accuracy: 0.2152\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.7646 - accuracy: 0.2212 - val_loss: 1.7038 - val_accuracy: 0.2244\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.6648 - accuracy: 0.2316 - val_loss: 1.6302 - val_accuracy: 0.2353\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 1.5969 - accuracy: 0.2392 - val_loss: 1.5684 - val_accuracy: 0.2413\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.5444 - accuracy: 0.2429 - val_loss: 1.5257 - val_accuracy: 0.2421\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 1.5092 - accuracy: 0.2445 - val_loss: 1.4969 - val_accuracy: 0.2429\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.4842 - accuracy: 0.2457 - val_loss: 1.4749 - val_accuracy: 0.2430\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 1.4641 - accuracy: 0.2461 - val_loss: 1.4567 - val_accuracy: 0.2449\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 1.4473 - accuracy: 0.2484 - val_loss: 1.4412 - val_accuracy: 0.2461\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.4337 - accuracy: 0.2496 - val_loss: 1.4292 - val_accuracy: 0.2485\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 1.4233 - accuracy: 0.2500 - val_loss: 1.4201 - val_accuracy: 0.2495\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 1.4154 - accuracy: 0.2522 - val_loss: 1.4130 - val_accuracy: 0.2490\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 1.4092 - accuracy: 0.2524 - val_loss: 1.4077 - val_accuracy: 0.2493\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 1.4045 - accuracy: 0.2532 - val_loss: 1.4035 - val_accuracy: 0.2488\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 1.4011 - accuracy: 0.2537 - val_loss: 1.4008 - val_accuracy: 0.2491\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 1.3984 - accuracy: 0.2546 - val_loss: 1.3983 - val_accuracy: 0.2488\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 1.3964 - accuracy: 0.2550 - val_loss: 1.3965 - val_accuracy: 0.2495\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 1.3948 - accuracy: 0.2551 - val_loss: 1.3953 - val_accuracy: 0.2499\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 1.3935 - accuracy: 0.2557 - val_loss: 1.3943 - val_accuracy: 0.2492\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 5s 60ms/step - loss: 1.3926 - accuracy: 0.2558 - val_loss: 1.3933 - val_accuracy: 0.2508\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 1.3917 - accuracy: 0.2559 - val_loss: 1.3929 - val_accuracy: 0.2516\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 5s 63ms/step - loss: 1.3911 - accuracy: 0.2565 - val_loss: 1.3920 - val_accuracy: 0.2486\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 1.3905 - accuracy: 0.2569 - val_loss: 1.3918 - val_accuracy: 0.2500\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 5s 67ms/step - loss: 1.3899 - accuracy: 0.2577 - val_loss: 1.3909 - val_accuracy: 0.2499\n",
      "Training data loss: 1.389680, accuracy: 0.257805\n",
      "Test data loss: 1.390970, accuracy: 0.249714\n",
      "Training the model with n_dense = (120, 120) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 7s 78ms/step - loss: 2.6118 - accuracy: 0.1384 - val_loss: 2.2579 - val_accuracy: 0.1856\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.9729 - accuracy: 0.2085 - val_loss: 1.7776 - val_accuracy: 0.2198\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 1.6953 - accuracy: 0.2311 - val_loss: 1.6334 - val_accuracy: 0.2397\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 6s 74ms/step - loss: 1.5950 - accuracy: 0.2413 - val_loss: 1.5633 - val_accuracy: 0.2434\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 6s 76ms/step - loss: 1.5404 - accuracy: 0.2449 - val_loss: 1.5217 - val_accuracy: 0.2445\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 6s 76ms/step - loss: 1.5059 - accuracy: 0.2460 - val_loss: 1.4935 - val_accuracy: 0.2446\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.4822 - accuracy: 0.2466 - val_loss: 1.4734 - val_accuracy: 0.2455\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.4634 - accuracy: 0.2478 - val_loss: 1.4557 - val_accuracy: 0.2463\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 1.4460 - accuracy: 0.2501 - val_loss: 1.4389 - val_accuracy: 0.2474\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 6s 76ms/step - loss: 1.4305 - accuracy: 0.2518 - val_loss: 1.4250 - val_accuracy: 0.2483\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.4183 - accuracy: 0.2534 - val_loss: 1.4147 - val_accuracy: 0.2489\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 6s 72ms/step - loss: 1.4098 - accuracy: 0.2548 - val_loss: 1.4080 - val_accuracy: 0.2495\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 7s 88ms/step - loss: 1.4041 - accuracy: 0.2560 - val_loss: 1.4035 - val_accuracy: 0.2493\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 1.4002 - accuracy: 0.2558 - val_loss: 1.4005 - val_accuracy: 0.2508\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 7s 83ms/step - loss: 1.3975 - accuracy: 0.2573 - val_loss: 1.3981 - val_accuracy: 0.2502\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 6s 76ms/step - loss: 1.3954 - accuracy: 0.2570 - val_loss: 1.3962 - val_accuracy: 0.2497\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 1.3936 - accuracy: 0.2587 - val_loss: 1.3947 - val_accuracy: 0.2499\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 1.3924 - accuracy: 0.2594 - val_loss: 1.3940 - val_accuracy: 0.2500\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 1.3913 - accuracy: 0.2601 - val_loss: 1.3929 - val_accuracy: 0.2495\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 7s 85ms/step - loss: 1.3905 - accuracy: 0.2605 - val_loss: 1.3923 - val_accuracy: 0.2501\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.3898 - accuracy: 0.2612 - val_loss: 1.3916 - val_accuracy: 0.2507\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 1.3892 - accuracy: 0.2613 - val_loss: 1.3920 - val_accuracy: 0.2495\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.3888 - accuracy: 0.2613 - val_loss: 1.3910 - val_accuracy: 0.2506\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 1.3884 - accuracy: 0.2615 - val_loss: 1.3908 - val_accuracy: 0.2502\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 1.3879 - accuracy: 0.2631 - val_loss: 1.3906 - val_accuracy: 0.2505\n",
      "Training data loss: 1.388128, accuracy: 0.261557\n",
      "Test data loss: 1.390782, accuracy: 0.250342\n",
      "Training the model with n_dense = (160, 160) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 9s 98ms/step - loss: 2.5076 - accuracy: 0.1549 - val_loss: 2.0582 - val_accuracy: 0.2080\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 1.8212 - accuracy: 0.2206 - val_loss: 1.6953 - val_accuracy: 0.2299\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 8s 102ms/step - loss: 1.6382 - accuracy: 0.2376 - val_loss: 1.5924 - val_accuracy: 0.2403\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 9s 111ms/step - loss: 1.5573 - accuracy: 0.2442 - val_loss: 1.5308 - val_accuracy: 0.2431\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 8s 104ms/step - loss: 1.5082 - accuracy: 0.2464 - val_loss: 1.4913 - val_accuracy: 0.2459\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 1.4751 - accuracy: 0.2478 - val_loss: 1.4633 - val_accuracy: 0.2450\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 1.4511 - accuracy: 0.2497 - val_loss: 1.4432 - val_accuracy: 0.2471\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.4341 - accuracy: 0.2531 - val_loss: 1.4288 - val_accuracy: 0.2484\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.4217 - accuracy: 0.2543 - val_loss: 1.4184 - val_accuracy: 0.2486\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 1.4127 - accuracy: 0.2561 - val_loss: 1.4106 - val_accuracy: 0.2510\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 8s 99ms/step - loss: 1.4059 - accuracy: 0.2566 - val_loss: 1.4048 - val_accuracy: 0.2510\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 8s 95ms/step - loss: 1.4012 - accuracy: 0.2581 - val_loss: 1.4018 - val_accuracy: 0.2498\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.3978 - accuracy: 0.2588 - val_loss: 1.3986 - val_accuracy: 0.2500\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 1.3952 - accuracy: 0.2599 - val_loss: 1.3965 - val_accuracy: 0.2514\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 1.3934 - accuracy: 0.2597 - val_loss: 1.3949 - val_accuracy: 0.2498\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 1.3918 - accuracy: 0.2608 - val_loss: 1.3939 - val_accuracy: 0.2510\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 1.3906 - accuracy: 0.2627 - val_loss: 1.3932 - val_accuracy: 0.2497\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 8s 96ms/step - loss: 1.3897 - accuracy: 0.2626 - val_loss: 1.3922 - val_accuracy: 0.2508\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 1.3888 - accuracy: 0.2636 - val_loss: 1.3920 - val_accuracy: 0.2517\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 1.3882 - accuracy: 0.2645 - val_loss: 1.3917 - val_accuracy: 0.2513\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 8s 100ms/step - loss: 1.3879 - accuracy: 0.2643 - val_loss: 1.3915 - val_accuracy: 0.2522\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 8s 95ms/step - loss: 1.3874 - accuracy: 0.2649 - val_loss: 1.3913 - val_accuracy: 0.2506\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 8s 98ms/step - loss: 1.3869 - accuracy: 0.2660 - val_loss: 1.3907 - val_accuracy: 0.2514\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 8s 97ms/step - loss: 1.3864 - accuracy: 0.2672 - val_loss: 1.3906 - val_accuracy: 0.2507\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 8s 101ms/step - loss: 1.3861 - accuracy: 0.2674 - val_loss: 1.3904 - val_accuracy: 0.2510\n",
      "Training data loss: 1.386252, accuracy: 0.266239\n",
      "Test data loss: 1.390439, accuracy: 0.250205\n",
      "Training the model with n_dense = (200, 200) layers:\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 12s 142ms/step - loss: 2.3926 - accuracy: 0.1646 - val_loss: 1.9239 - val_accuracy: 0.2137\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.7500 - accuracy: 0.2256 - val_loss: 1.6617 - val_accuracy: 0.2332\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.6025 - accuracy: 0.2403 - val_loss: 1.5549 - val_accuracy: 0.2412\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.5218 - accuracy: 0.2454 - val_loss: 1.4988 - val_accuracy: 0.2436\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 10s 122ms/step - loss: 1.4802 - accuracy: 0.2480 - val_loss: 1.4678 - val_accuracy: 0.2440\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 9s 118ms/step - loss: 1.4546 - accuracy: 0.2500 - val_loss: 1.4472 - val_accuracy: 0.2458\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 1.4367 - accuracy: 0.2520 - val_loss: 1.4316 - val_accuracy: 0.2469\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 11s 138ms/step - loss: 1.4233 - accuracy: 0.2547 - val_loss: 1.4205 - val_accuracy: 0.2475\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 1.4139 - accuracy: 0.2573 - val_loss: 1.4128 - val_accuracy: 0.2496\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 10s 129ms/step - loss: 1.4078 - accuracy: 0.2583 - val_loss: 1.4080 - val_accuracy: 0.2496\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 10s 128ms/step - loss: 1.4035 - accuracy: 0.2594 - val_loss: 1.4043 - val_accuracy: 0.2498\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 10s 131ms/step - loss: 1.4000 - accuracy: 0.2605 - val_loss: 1.4016 - val_accuracy: 0.2505\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 12s 146ms/step - loss: 1.3977 - accuracy: 0.2611 - val_loss: 1.3997 - val_accuracy: 0.2514\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 11s 134ms/step - loss: 1.3955 - accuracy: 0.2623 - val_loss: 1.3979 - val_accuracy: 0.2500\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 10s 124ms/step - loss: 1.3937 - accuracy: 0.2633 - val_loss: 1.3965 - val_accuracy: 0.2503\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 10s 126ms/step - loss: 1.3923 - accuracy: 0.2645 - val_loss: 1.3956 - val_accuracy: 0.2517\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 10s 127ms/step - loss: 1.3911 - accuracy: 0.2650 - val_loss: 1.3947 - val_accuracy: 0.2505\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 10s 123ms/step - loss: 1.3902 - accuracy: 0.2657 - val_loss: 1.3941 - val_accuracy: 0.2497\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.3895 - accuracy: 0.2663 - val_loss: 1.3938 - val_accuracy: 0.2515\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 10s 120ms/step - loss: 1.3886 - accuracy: 0.2669 - val_loss: 1.3935 - val_accuracy: 0.2507\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.3879 - accuracy: 0.2682 - val_loss: 1.3930 - val_accuracy: 0.2497\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.3874 - accuracy: 0.2690 - val_loss: 1.3925 - val_accuracy: 0.2502\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 10s 121ms/step - loss: 1.3869 - accuracy: 0.2691 - val_loss: 1.3929 - val_accuracy: 0.2500\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3865 - accuracy: 0.2699 - val_loss: 1.3925 - val_accuracy: 0.2507\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 10s 119ms/step - loss: 1.3859 - accuracy: 0.2710 - val_loss: 1.3919 - val_accuracy: 0.2501\n",
      "Training data loss: 1.386210, accuracy: 0.270189\n",
      "Test data loss: 1.391927, accuracy: 0.250150\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "val_split = 0.2\n",
    "n_epochs = 25\n",
    "for model in models_wpym:\n",
    "  print(f\"Training the model with n_dense = ({nnodes[i]}, {nnodes[i]}) layers:\")\n",
    "  history = model.fit(feature_bits_train_wpym, class_bits_train_wpym, epochs=n_epochs, batch_size=10000, validation_split=val_split)\n",
    "  test_model(model, feature_bits_train_wpym, class_bits_train_wpym, feature_bits_test_wpym, class_bits_test_wpym)\n",
    "  i=i+1\n",
    "i=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the predictions with PyMatching input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 28ms/step\n",
      "500/500 [==============================] - 12s 23ms/step\n",
      "Number of wrong training bitmap predictions: 747900 / 1000000\n",
      "Number of wrong test bitmap predictions: 3751978 / 5000000\n",
      "Number of wrong training XOR predictions: 1650 / 1000000\n",
      "Number of wrong test XOR predictions: 8646 / 5000000\n",
      "100/100 [==============================] - 3s 28ms/step\n",
      "500/500 [==============================] - 15s 29ms/step\n",
      "Number of wrong training bitmap predictions: 742194 / 1000000\n",
      "Number of wrong test bitmap predictions: 3751428 / 5000000\n",
      "Number of wrong training XOR predictions: 64 / 1000000\n",
      "Number of wrong test XOR predictions: 404 / 5000000\n",
      "100/100 [==============================] - 4s 38ms/step\n",
      "500/500 [==============================] - 24s 47ms/step\n",
      "Number of wrong training bitmap predictions: 738443 / 1000000\n",
      "Number of wrong test bitmap predictions: 3748292 / 5000000\n",
      "Number of wrong training XOR predictions: 21 / 1000000\n",
      "Number of wrong test XOR predictions: 199 / 5000000\n",
      "100/100 [==============================] - 5s 44ms/step\n",
      "500/500 [==============================] - 21s 41ms/step\n",
      "Number of wrong training bitmap predictions: 733761 / 1000000\n",
      "Number of wrong test bitmap predictions: 3748970 / 5000000\n",
      "Number of wrong training XOR predictions: 43 / 1000000\n",
      "Number of wrong test XOR predictions: 298 / 5000000\n",
      "100/100 [==============================] - 11s 104ms/step\n",
      "500/500 [==============================] - 45s 89ms/step\n",
      "Number of wrong training bitmap predictions: 729811 / 1000000\n",
      "Number of wrong test bitmap predictions: 3749252 / 5000000\n",
      "Number of wrong training XOR predictions: 115 / 1000000\n",
      "Number of wrong test XOR predictions: 637 / 5000000\n"
     ]
    }
   ],
   "source": [
    "# Keep track of the number of wrong bitmap predictions\n",
    "n_wrong_class_wpym_train = np.zeros(len(models_wpym), dtype=np.int32)\n",
    "n_wrong_class_wpym_test = np.zeros(len(models_wpym), dtype=np.int32)\n",
    "# Keep track of the number of actual XOR flip predictions\n",
    "n_wrong_XOR_wpym_train = np.zeros(len(models_wpym), dtype=np.int32)\n",
    "n_wrong_XOR_wpym_test = np.zeros(len(models_wpym), dtype=np.int32)\n",
    "\n",
    "imodel = 0\n",
    "for model in models_wpym:\n",
    "  tmp = model.predict(feature_bits_train_wpym, batch_size=10000)\n",
    "  for i in range(tmp.shape[0]):\n",
    "    jp = 0\n",
    "    vjp = 0.\n",
    "    for j in range(tmp.shape[1]):\n",
    "      if tmp[i][j]>vjp:\n",
    "        vjp = tmp[i][j]\n",
    "        jp = j\n",
    "    if class_bits_train_wpym[i] != jp:\n",
    "      n_wrong_class_wpym_train[imodel] = n_wrong_class_wpym_train[imodel] + 1\n",
    "    has_flip_truth = get_XOR_prediction(class_bits_train_wpym[i])\n",
    "    has_flip_pred = get_XOR_prediction(jp)\n",
    "    if has_flip_pred != has_flip_truth:\n",
    "      n_wrong_XOR_wpym_train[imodel] = n_wrong_XOR_wpym_train[imodel] + 1\n",
    "    \n",
    "  tmp = model.predict(feature_bits_test_wpym, batch_size=10000)\n",
    "  for i in range(tmp.shape[0]):\n",
    "    jp = 0\n",
    "    vjp = 0.\n",
    "    for j in range(tmp.shape[1]):\n",
    "      if tmp[i][j]>vjp:\n",
    "        vjp = tmp[i][j]\n",
    "        jp = j\n",
    "    if class_bits_test_wpym[i] != jp:\n",
    "      n_wrong_class_wpym_test[imodel] = n_wrong_class_wpym_test[imodel] + 1\n",
    "    has_flip_truth = get_XOR_prediction(class_bits_test_wpym[i])\n",
    "    has_flip_pred = get_XOR_prediction(jp)\n",
    "    if has_flip_pred != has_flip_truth:\n",
    "      n_wrong_XOR_wpym_test[imodel] = n_wrong_XOR_wpym_test[imodel] + 1\n",
    "\n",
    "  print(f\"Number of wrong training bitmap predictions: {n_wrong_class_wpym_train[imodel]} / {feature_bits_train_wpym.shape[0]}\")\n",
    "  print(f\"Number of wrong test bitmap predictions: {n_wrong_class_wpym_test[imodel]} / {feature_bits_test_wpym.shape[0]}\")\n",
    "  print(f\"Number of wrong training XOR predictions: {n_wrong_XOR_wpym_train[imodel]} / {feature_bits_train_wpym.shape[0]}\")\n",
    "  print(f\"Number of wrong test XOR predictions: {n_wrong_XOR_wpym_test[imodel]} / {feature_bits_test_wpym.shape[0]}\")\n",
    "  imodel = imodel + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to get quantiles and uncertainties in efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2 as chisq\n",
    "from scipy.stats import binomtest\n",
    "\n",
    "chisquared_cdf = chisq.cdf\n",
    "chisquared_quantile = chisq.ppf\n",
    "\n",
    "def get_CL_for_ndof(m2dll, ndof):\n",
    "  return chisquared_cdf(m2dll, df=ndof)\n",
    "\n",
    "VAL_CL_1SIGMA = get_CL_for_ndof(1., 1)\n",
    "VAL_CL_2SIGMA = get_CL_for_ndof(4., 1)\n",
    "\n",
    "def counting_interval(sw_total, swsq_total=None, CL = VAL_CL_1SIGMA):\n",
    "  quant = (1.-CL)/2.\n",
    "  count = 0.\n",
    "  if swsq_total is None or swsq_total<=0.:\n",
    "    count = sw_total\n",
    "  else:\n",
    "    count = sw_total**2/swsq_total\n",
    "  vlow = (chisquared_quantile(quant, 2.*count) / 2. if count!=0. else 0.)\n",
    "  vhigh = chisquared_quantile(1.-quant, 2.*(count+1.)) / 2.\n",
    "  if count>0.:\n",
    "    vlow = vlow * sw_total / count\n",
    "    vhigh = vhigh * sw_total / count\n",
    "  return (vlow, vhigh)\n",
    "\n",
    "def efficiency_interval(sw_passed, sw_total, swsq_total=None, CL = VAL_CL_1SIGMA):\n",
    "  normval = 1.\n",
    "  if swsq_total is not None and swsq_total>0.:\n",
    "    normval = sw_total/swsq_total\n",
    "  passed = np.int32(sw_passed*normval)\n",
    "  total = np.int32(sw_total*normval)\n",
    "  ci = binomtest(k=passed, n=total).proportion_ci(method='exact', confidence_level=CL)\n",
    "  return (ci.low, ci.high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot to compare the prediction inaccuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "eff_wrong_XOR_nnonly_test = np.zeros(shape=(n_wrong_XOR_nnonly_test.shape[0],3), dtype=np.float32)\n",
    "eff_wrong_XOR_wpym_test = np.zeros(shape=(n_wrong_XOR_wpym_test.shape[0],3), dtype=np.float32)\n",
    "for iev in range(n_wrong_XOR_nnonly_test.shape[0]):\n",
    "  eff_wrong_XOR_nnonly_test[iev][0] = np.float32(n_wrong_XOR_nnonly_test[iev]/feature_bits_test.shape[0])\n",
    "  eff_wrong_XOR_wpym_test[iev][0] = np.float32(n_wrong_XOR_wpym_test[iev]/feature_bits_test_wpym.shape[0])\n",
    "  eff_wrong_XOR_nnonly_test[iev][1], eff_wrong_XOR_nnonly_test[iev][2] = np.float32(efficiency_interval(n_wrong_XOR_nnonly_test[iev], feature_bits_test.shape[0]))\n",
    "  eff_wrong_XOR_wpym_test[iev][1], eff_wrong_XOR_wpym_test[iev][2] = np.float32(efficiency_interval(n_wrong_XOR_wpym_test[iev], feature_bits_test_wpym.shape[0]))\n",
    "\n",
    "incorrect_pym_rate = np.sum(incorrect_matches.reshape(-1,), dtype=np.float32)/incorrect_matches.shape[0]\n",
    "avg_flips = np.sum(flips.reshape(-1,), dtype=np.float32)/flips.shape[0]\n",
    "\n",
    "ax.errorbar(\n",
    "  x=nnodes,\n",
    "  y=eff_wrong_XOR_nnonly_test[:,0],\n",
    "  yerr=[\n",
    "    eff_wrong_XOR_nnonly_test[:,0]-eff_wrong_XOR_nnonly_test[:,1],\n",
    "    eff_wrong_XOR_nnonly_test[:,2]-eff_wrong_XOR_nnonly_test[:,0]\n",
    "  ],\n",
    "  fmt='o',\n",
    "  label='NN only',\n",
    "  markersize=2\n",
    ")\n",
    "ax.errorbar(\n",
    "  x=nnodes,\n",
    "  y=eff_wrong_XOR_wpym_test[:,0],\n",
    "  yerr=[\n",
    "    eff_wrong_XOR_wpym_test[:,0]-eff_wrong_XOR_wpym_test[:,1],\n",
    "    eff_wrong_XOR_wpym_test[:,2]-eff_wrong_XOR_wpym_test[:,0]\n",
    "  ],\n",
    "  fmt='o',\n",
    "  label='NN after pyMatching',\n",
    "  markersize=2\n",
    ")\n",
    "ax.axhline(y=incorrect_pym_rate, color='r', linestyle='--', label=f'PyMatching 2 ({incorrect_pym_rate*100.:.1f}%)')\n",
    "ax.set_xlabel('Number of nodes per layer')\n",
    "ax.set_ylabel('Misprediction fraction')\n",
    "ax.set_title(f'Misprediction of XOR flips\\n(1% noise prob., avg. noise rate: {avg_flips*100.:.0f}%)')\n",
    "ax.legend()\n",
    "ax.set_ylim([1e-7, 1e-1])\n",
    "ax.set_yscale('log')\n",
    "fig.set_dpi(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
