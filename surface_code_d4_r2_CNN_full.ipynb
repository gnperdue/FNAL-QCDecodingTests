{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pymatching\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from circuit_generators import *\n",
    "from sampling_functions import *\n",
    "from bitpack import pack_bits, unpack_bits\n",
    "from circuit_partition import *\n",
    "from utilities_tf import *\n",
    "\n",
    "\n",
    "# Number of worker nodes\n",
    "n_worker_nodes = 8\n",
    "\n",
    "# Surface code specifications\n",
    "d = 4\n",
    "r = 2\n",
    "kernel_size = 3\n",
    "p = 0.01\n",
    "use_rotated_z = True\n",
    "observable_type = \"ZL\" if use_rotated_z else \"XL\"\n",
    "\n",
    "# Bit types\n",
    "binary_t = np.int8 # Could use even less if numpy allowed\n",
    "packed_t = np.int8 # Packed bit type\n",
    "if d<=8:\n",
    "  pass\n",
    "elif d>8 and d<=16:\n",
    "  packed_t = np.int16\n",
    "elif d>16 and d<=32:\n",
    "  packed_t = np.int32\n",
    "elif d>32 and d<=64:\n",
    "  packed_t = np.int64\n",
    "elif d>64 and d<=128:\n",
    "  packed_t = np.int128\n",
    "elif d>128 and d<=256:\n",
    "  packed_t = np.int256\n",
    "else:\n",
    "  raise RuntimeError(\"d is too large.\")\n",
    "time_t = np.int8\n",
    "\n",
    "# Measurement index type\n",
    "idx_t = np.int8\n",
    "n_all_measurements = r*(d**2-1) + d**2\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int16\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int32\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int64\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int128\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  idx_t = np.int256\n",
    "if n_all_measurements > np.iinfo(idx_t).max:\n",
    "  raise RuntimeError(\"idx_t is too small.\")\n",
    "\n",
    "# Call signature for circuit_partition::group_det_bits_kxk\n",
    "call_group_det_bits_kxk = lambda det_bits_dxd, data_bits_dxd=None, d=d, r=r, k=kernel_size, use_rotated_z=use_rotated_z, binary_t=binary_t, idx_t=idx_t: group_det_bits_kxk(det_bits_dxd, d, r, k, use_rotated_z, data_bits_dxd, binary_t, idx_t)\n",
    "\n",
    "# Call signature for bitpack::pack_bits\n",
    "call_pack_bits = lambda bits, packed_t=packed_t: pack_bits(bits, bits.shape[0], packed_t=packed_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average flip rate for the full circuit: 0.19171115\n"
     ]
    }
   ],
   "source": [
    "n_test = 10000000\n",
    "n_train = 10000000\n",
    "n_samples = n_test + n_train\n",
    "decoders = ['pymatching']\n",
    "test_circuit = get_builtin_circuit(\n",
    "  \"surface_code:rotated_memory_\"+('z' if use_rotated_z else 'x'),\n",
    "  distance=d,\n",
    "  rounds=r,\n",
    "  before_round_data_depolarization = p,\n",
    "  after_reset_flip_probability = p,\n",
    "  after_clifford_depolarization = p,\n",
    "  before_measure_flip_probability = p\n",
    ")\n",
    "\n",
    "kernel_circuit = stim.Circuit(\n",
    "  f\"\"\"\n",
    "QUBIT_COORDS(1, 1) 1\n",
    "QUBIT_COORDS(2, 0) 2\n",
    "QUBIT_COORDS(3, 1) 3\n",
    "QUBIT_COORDS(5, 1) 5\n",
    "QUBIT_COORDS(1, 3) 8\n",
    "QUBIT_COORDS(2, 2) 9\n",
    "QUBIT_COORDS(3, 3) 10\n",
    "QUBIT_COORDS(4, 2) 11\n",
    "QUBIT_COORDS(5, 3) 12\n",
    "QUBIT_COORDS(6, 2) 13\n",
    "QUBIT_COORDS(0, 4) 14\n",
    "QUBIT_COORDS(1, 5) 15\n",
    "QUBIT_COORDS(2, 4) 16\n",
    "QUBIT_COORDS(3, 5) 17\n",
    "QUBIT_COORDS(4, 4) 18\n",
    "QUBIT_COORDS(5, 5) 19\n",
    "QUBIT_COORDS(4, 6) 25\n",
    "R 1 3 5 8 10 12 15 17 19\n",
    "X_ERROR(0.01) 1 3 5 8 10 12 15 17 19\n",
    "R 2 9 11 13 14 16 18 25\n",
    "X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
    "TICK\n",
    "DEPOLARIZE1(0.01) 1 3 5 8 10 12 15 17 19\n",
    "H 2 11 16 25\n",
    "DEPOLARIZE1(0.01) 2 11 16 25\n",
    "TICK\n",
    "CX 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "DEPOLARIZE2(0.01) 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "DEPOLARIZE1(0.01) 13 25\n",
    "TICK\n",
    "CX 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "DEPOLARIZE2(0.01) 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "DEPOLARIZE1(0.01) 5 13 17 19 25\n",
    "TICK\n",
    "CX 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "DEPOLARIZE2(0.01) 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "#DEPOLARIZE1(0.01)\n",
    "TICK\n",
    "CX 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "DEPOLARIZE2(0.01) 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "DEPOLARIZE1(0.01) 12 15 19\n",
    "TICK\n",
    "H 2 11 16 25\n",
    "DEPOLARIZE1(0.01) 2 11 16 25\n",
    "TICK\n",
    "X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
    "MR 2 9 11 13 14 16 18 25\n",
    "X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
    "DETECTOR(0, 4, 0) rec[-4]\n",
    "DETECTOR(2, 2, 0) rec[-7]\n",
    "DETECTOR(4, 4, 0) rec[-2]\n",
    "DETECTOR(6, 2, 0) rec[-5]\n",
    "REPEAT {r-1} {{\n",
    "  TICK\n",
    "  DEPOLARIZE1(0.01) 1 3 5 8 10 12 15 17 19\n",
    "  H 2 11 16 25\n",
    "  DEPOLARIZE1(0.01) 2 11 16 25\n",
    "  TICK\n",
    "  CX 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "  DEPOLARIZE2(0.01) 2 3 16 17 11 12 15 14 10 9 19 18\n",
    "  DEPOLARIZE1(0.01) 13 25\n",
    "  TICK\n",
    "  CX 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "  DEPOLARIZE2(0.01) 2 1 16 15 11 10 8 14 3 9 12 18\n",
    "  DEPOLARIZE1(0.01) 5 13 17 19 25\n",
    "  TICK\n",
    "  CX 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "  DEPOLARIZE2(0.01) 16 10 11 5 25 19 8 9 17 18 12 13\n",
    "  #DEPOLARIZE1(0.01)\n",
    "  TICK\n",
    "  CX 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "  DEPOLARIZE2(0.01) 16 8 11 3 25 17 1 9 10 18 5 13\n",
    "  DEPOLARIZE1(0.01) 12 15 19\n",
    "  TICK\n",
    "  H 2 11 16 25\n",
    "  DEPOLARIZE1(0.01) 2 11 16 25\n",
    "  TICK\n",
    "  X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
    "  MR 2 9 11 13 14 16 18 25\n",
    "  X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
    "  SHIFT_COORDS(0, 0, 1)\n",
    "  DETECTOR(2, 0, 0) rec[-8] rec[-16]\n",
    "  DETECTOR(2, 2, 0) rec[-7] rec[-15]\n",
    "  DETECTOR(4, 2, 0) rec[-6] rec[-14]\n",
    "  DETECTOR(6, 2, 0) rec[-5] rec[-13]\n",
    "  DETECTOR(0, 4, 0) rec[-4] rec[-12]\n",
    "  DETECTOR(2, 4, 0) rec[-3] rec[-11]\n",
    "  DETECTOR(4, 4, 0) rec[-2] rec[-10]\n",
    "  DETECTOR(4, 6, 0) rec[-1] rec[-9]\n",
    "}}\n",
    "X_ERROR(0.01) 1 3 5 8 10 12 15 17 19\n",
    "M 1 3 5 8 10 12 15 17 19\n",
    "DETECTOR(0, 4, 1) rec[-3] rec[-6] rec[-13]\n",
    "DETECTOR(2, 2, 1) rec[-5] rec[-6] rec[-8] rec[-9] rec[-16]\n",
    "DETECTOR(4, 4, 1) rec[-1] rec[-2] rec[-4] rec[-5] rec[-11]\n",
    "DETECTOR(6, 2, 1) rec[-4] rec[-7] rec[-14]\n",
    "OBSERVABLE_INCLUDE(0) rec[-7] rec[-8] rec[-9]\n",
    "  \"\"\"\n",
    ")\n",
    "\n",
    "# Sampling for the dxd circuit\n",
    "m_sampler = test_circuit.compile_sampler(seed=12345)\n",
    "d_sampler = test_circuit.compile_detector_sampler(seed=12345)\n",
    "converter = test_circuit.compile_m2d_converter()\n",
    "detector_error_model = test_circuit.detector_error_model(decompose_errors=True)\n",
    "\n",
    "measurements = m_sampler.sample(n_samples, bit_packed=False)\n",
    "det_evts, flips = converter.convert(measurements=measurements, separate_observables=True, bit_packed=False)\n",
    "measurements = measurements.astype(binary_t)\n",
    "det_evts = det_evts.astype(binary_t)\n",
    "flips = flips.astype(binary_t)\n",
    "\n",
    "avg_flips = np.sum(flips.reshape(-1,), dtype=np.float32)/flips.shape[0]\n",
    "print(f\"Average flip rate for the full circuit: {avg_flips}\")\n",
    "\n",
    "# Sampling for the kxk kernel\n",
    "m_sampler_kernel = kernel_circuit.compile_sampler(seed=12345)\n",
    "d_sampler_kernel = kernel_circuit.compile_detector_sampler(seed=12345)\n",
    "converter_kernel = kernel_circuit.compile_m2d_converter()\n",
    "detector_error_model_kernel = kernel_circuit.detector_error_model(decompose_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUBIT_COORDS(1, 1) 1\n",
      "QUBIT_COORDS(2, 0) 2\n",
      "QUBIT_COORDS(3, 1) 3\n",
      "QUBIT_COORDS(5, 1) 5\n",
      "QUBIT_COORDS(6, 0) 6\n",
      "QUBIT_COORDS(7, 1) 7\n",
      "QUBIT_COORDS(1, 3) 10\n",
      "QUBIT_COORDS(2, 2) 11\n",
      "QUBIT_COORDS(3, 3) 12\n",
      "QUBIT_COORDS(4, 2) 13\n",
      "QUBIT_COORDS(5, 3) 14\n",
      "QUBIT_COORDS(6, 2) 15\n",
      "QUBIT_COORDS(7, 3) 16\n",
      "QUBIT_COORDS(0, 4) 18\n",
      "QUBIT_COORDS(1, 5) 19\n",
      "QUBIT_COORDS(2, 4) 20\n",
      "QUBIT_COORDS(3, 5) 21\n",
      "QUBIT_COORDS(4, 4) 22\n",
      "QUBIT_COORDS(5, 5) 23\n",
      "QUBIT_COORDS(6, 4) 24\n",
      "QUBIT_COORDS(7, 5) 25\n",
      "QUBIT_COORDS(8, 4) 26\n",
      "QUBIT_COORDS(1, 7) 28\n",
      "QUBIT_COORDS(2, 6) 29\n",
      "QUBIT_COORDS(3, 7) 30\n",
      "QUBIT_COORDS(4, 6) 31\n",
      "QUBIT_COORDS(5, 7) 32\n",
      "QUBIT_COORDS(6, 6) 33\n",
      "QUBIT_COORDS(7, 7) 34\n",
      "QUBIT_COORDS(2, 8) 38\n",
      "QUBIT_COORDS(6, 8) 42\n",
      "R 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "X_ERROR(0.01) 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "R 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "TICK\n",
      "DEPOLARIZE1(0.01) 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "H 2 6 13 20 24 31 38 42\n",
      "DEPOLARIZE1(0.01) 2 6 13 20 24 31 38 42\n",
      "TICK\n",
      "CX 2 3 20 21 13 14 31 32 6 7 24 25 19 18 12 11 30 29 23 22 16 15 34 33\n",
      "DEPOLARIZE2(0.01) 2 3 20 21 13 14 31 32 6 7 24 25 19 18 12 11 30 29 23 22 16 15 34 33\n",
      "TICK\n",
      "CX 2 1 20 19 13 12 31 30 6 5 24 23 10 18 3 11 21 29 14 22 7 15 25 33\n",
      "DEPOLARIZE2(0.01) 2 1 20 19 13 12 31 30 6 5 24 23 10 18 3 11 21 29 14 22 7 15 25 33\n",
      "TICK\n",
      "CX 20 12 38 30 13 5 31 23 24 16 42 34 10 11 28 29 21 22 14 15 32 33 25 26\n",
      "DEPOLARIZE2(0.01) 20 12 38 30 13 5 31 23 24 16 42 34 10 11 28 29 21 22 14 15 32 33 25 26\n",
      "TICK\n",
      "CX 20 10 38 28 13 3 31 21 24 14 42 32 1 11 19 29 12 22 5 15 23 33 16 26\n",
      "DEPOLARIZE2(0.01) 20 10 38 28 13 3 31 21 24 14 42 32 1 11 19 29 12 22 5 15 23 33 16 26\n",
      "TICK\n",
      "H 2 6 13 20 24 31 38 42\n",
      "DEPOLARIZE1(0.01) 2 6 13 20 24 31 38 42\n",
      "TICK\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "MR 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "DETECTOR(0, 4, 0) rec[-10]\n",
      "DETECTOR(2, 2, 0) rec[-13]\n",
      "DETECTOR(2, 6, 0) rec[-5]\n",
      "DETECTOR(4, 4, 0) rec[-8]\n",
      "DETECTOR(6, 2, 0) rec[-11]\n",
      "DETECTOR(6, 6, 0) rec[-3]\n",
      "DETECTOR(8, 4, 0) rec[-6]\n",
      "TICK\n",
      "DEPOLARIZE1(0.01) 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "H 2 6 13 20 24 31 38 42\n",
      "DEPOLARIZE1(0.01) 2 6 13 20 24 31 38 42\n",
      "TICK\n",
      "CX 2 3 20 21 13 14 31 32 6 7 24 25 19 18 12 11 30 29 23 22 16 15 34 33\n",
      "DEPOLARIZE2(0.01) 2 3 20 21 13 14 31 32 6 7 24 25 19 18 12 11 30 29 23 22 16 15 34 33\n",
      "TICK\n",
      "CX 2 1 20 19 13 12 31 30 6 5 24 23 10 18 3 11 21 29 14 22 7 15 25 33\n",
      "DEPOLARIZE2(0.01) 2 1 20 19 13 12 31 30 6 5 24 23 10 18 3 11 21 29 14 22 7 15 25 33\n",
      "TICK\n",
      "CX 20 12 38 30 13 5 31 23 24 16 42 34 10 11 28 29 21 22 14 15 32 33 25 26\n",
      "DEPOLARIZE2(0.01) 20 12 38 30 13 5 31 23 24 16 42 34 10 11 28 29 21 22 14 15 32 33 25 26\n",
      "TICK\n",
      "CX 20 10 38 28 13 3 31 21 24 14 42 32 1 11 19 29 12 22 5 15 23 33 16 26\n",
      "DEPOLARIZE2(0.01) 20 10 38 28 13 3 31 21 24 14 42 32 1 11 19 29 12 22 5 15 23 33 16 26\n",
      "TICK\n",
      "H 2 6 13 20 24 31 38 42\n",
      "DEPOLARIZE1(0.01) 2 6 13 20 24 31 38 42\n",
      "TICK\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "MR 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "X_ERROR(0.01) 2 6 11 13 15 18 20 22 24 26 29 31 33 38 42\n",
      "SHIFT_COORDS(0, 0, 1)\n",
      "DETECTOR(2, 0, 0) rec[-15] rec[-30]\n",
      "DETECTOR(6, 0, 0) rec[-14] rec[-29]\n",
      "DETECTOR(2, 2, 0) rec[-13] rec[-28]\n",
      "DETECTOR(4, 2, 0) rec[-12] rec[-27]\n",
      "DETECTOR(6, 2, 0) rec[-11] rec[-26]\n",
      "DETECTOR(0, 4, 0) rec[-10] rec[-25]\n",
      "DETECTOR(2, 4, 0) rec[-9] rec[-24]\n",
      "DETECTOR(4, 4, 0) rec[-8] rec[-23]\n",
      "DETECTOR(6, 4, 0) rec[-7] rec[-22]\n",
      "DETECTOR(8, 4, 0) rec[-6] rec[-21]\n",
      "DETECTOR(2, 6, 0) rec[-5] rec[-20]\n",
      "DETECTOR(4, 6, 0) rec[-4] rec[-19]\n",
      "DETECTOR(6, 6, 0) rec[-3] rec[-18]\n",
      "DETECTOR(2, 8, 0) rec[-2] rec[-17]\n",
      "DETECTOR(6, 8, 0) rec[-1] rec[-16]\n",
      "X_ERROR(0.01) 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "M 1 3 5 7 10 12 14 16 19 21 23 25 28 30 32 34\n",
      "DETECTOR(0, 4, 1) rec[-8] rec[-12] rec[-26]\n",
      "DETECTOR(2, 2, 1) rec[-11] rec[-12] rec[-15] rec[-16] rec[-29]\n",
      "DETECTOR(2, 6, 1) rec[-3] rec[-4] rec[-7] rec[-8] rec[-21]\n",
      "DETECTOR(4, 4, 1) rec[-6] rec[-7] rec[-10] rec[-11] rec[-24]\n",
      "DETECTOR(6, 2, 1) rec[-9] rec[-10] rec[-13] rec[-14] rec[-27]\n",
      "DETECTOR(6, 6, 1) rec[-1] rec[-2] rec[-5] rec[-6] rec[-19]\n",
      "DETECTOR(8, 4, 1) rec[-5] rec[-9] rec[-22]\n",
      "OBSERVABLE_INCLUDE(0) rec[-13] rec[-14] rec[-15] rec[-16]\n"
     ]
    }
   ],
   "source": [
    "print(test_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUBIT_COORDS(1, 1) 1\n",
      "QUBIT_COORDS(2, 0) 2\n",
      "QUBIT_COORDS(3, 1) 3\n",
      "QUBIT_COORDS(5, 1) 5\n",
      "QUBIT_COORDS(1, 3) 8\n",
      "QUBIT_COORDS(2, 2) 9\n",
      "QUBIT_COORDS(3, 3) 10\n",
      "QUBIT_COORDS(4, 2) 11\n",
      "QUBIT_COORDS(5, 3) 12\n",
      "QUBIT_COORDS(6, 2) 13\n",
      "QUBIT_COORDS(0, 4) 14\n",
      "QUBIT_COORDS(1, 5) 15\n",
      "QUBIT_COORDS(2, 4) 16\n",
      "QUBIT_COORDS(3, 5) 17\n",
      "QUBIT_COORDS(4, 4) 18\n",
      "QUBIT_COORDS(5, 5) 19\n",
      "QUBIT_COORDS(4, 6) 25\n",
      "R 1 3 5 8 10 12 15 17 19\n",
      "X_ERROR(0.01) 1 3 5 8 10 12 15 17 19\n",
      "R 2 9 11 13 14 16 18 25\n",
      "X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
      "TICK\n",
      "DEPOLARIZE1(0.01) 1 3 5 8 10 12 15 17 19\n",
      "H 2 11 16 25\n",
      "DEPOLARIZE1(0.01) 2 11 16 25\n",
      "TICK\n",
      "CX 2 3 16 17 11 12 15 14 10 9 19 18\n",
      "DEPOLARIZE2(0.01) 2 3 16 17 11 12 15 14 10 9 19 18\n",
      "DEPOLARIZE1(0.01) 13 25\n",
      "TICK\n",
      "CX 2 1 16 15 11 10 8 14 3 9 12 18\n",
      "DEPOLARIZE2(0.01) 2 1 16 15 11 10 8 14 3 9 12 18\n",
      "DEPOLARIZE1(0.01) 5 13 17 19 25\n",
      "TICK\n",
      "CX 16 10 11 5 25 19 8 9 17 18 12 13\n",
      "DEPOLARIZE2(0.01) 16 10 11 5 25 19 8 9 17 18 12 13\n",
      "TICK\n",
      "CX 16 8 11 3 25 17 1 9 10 18 5 13\n",
      "DEPOLARIZE2(0.01) 16 8 11 3 25 17 1 9 10 18 5 13\n",
      "DEPOLARIZE1(0.01) 12 15 19\n",
      "TICK\n",
      "H 2 11 16 25\n",
      "DEPOLARIZE1(0.01) 2 11 16 25\n",
      "TICK\n",
      "X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
      "MR 2 9 11 13 14 16 18 25\n",
      "X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
      "DETECTOR(0, 4, 0) rec[-4]\n",
      "DETECTOR(2, 2, 0) rec[-7]\n",
      "DETECTOR(4, 4, 0) rec[-2]\n",
      "DETECTOR(6, 2, 0) rec[-5]\n",
      "REPEAT 1 {\n",
      "    TICK\n",
      "    DEPOLARIZE1(0.01) 1 3 5 8 10 12 15 17 19\n",
      "    H 2 11 16 25\n",
      "    DEPOLARIZE1(0.01) 2 11 16 25\n",
      "    TICK\n",
      "    CX 2 3 16 17 11 12 15 14 10 9 19 18\n",
      "    DEPOLARIZE2(0.01) 2 3 16 17 11 12 15 14 10 9 19 18\n",
      "    DEPOLARIZE1(0.01) 13 25\n",
      "    TICK\n",
      "    CX 2 1 16 15 11 10 8 14 3 9 12 18\n",
      "    DEPOLARIZE2(0.01) 2 1 16 15 11 10 8 14 3 9 12 18\n",
      "    DEPOLARIZE1(0.01) 5 13 17 19 25\n",
      "    TICK\n",
      "    CX 16 10 11 5 25 19 8 9 17 18 12 13\n",
      "    DEPOLARIZE2(0.01) 16 10 11 5 25 19 8 9 17 18 12 13\n",
      "    TICK\n",
      "    CX 16 8 11 3 25 17 1 9 10 18 5 13\n",
      "    DEPOLARIZE2(0.01) 16 8 11 3 25 17 1 9 10 18 5 13\n",
      "    DEPOLARIZE1(0.01) 12 15 19\n",
      "    TICK\n",
      "    H 2 11 16 25\n",
      "    DEPOLARIZE1(0.01) 2 11 16 25\n",
      "    TICK\n",
      "    X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
      "    MR 2 9 11 13 14 16 18 25\n",
      "    X_ERROR(0.01) 2 9 11 13 14 16 18 25\n",
      "    SHIFT_COORDS(0, 0, 1)\n",
      "    DETECTOR(2, 0, 0) rec[-8] rec[-16]\n",
      "    DETECTOR(2, 2, 0) rec[-7] rec[-15]\n",
      "    DETECTOR(4, 2, 0) rec[-6] rec[-14]\n",
      "    DETECTOR(6, 2, 0) rec[-5] rec[-13]\n",
      "    DETECTOR(0, 4, 0) rec[-4] rec[-12]\n",
      "    DETECTOR(2, 4, 0) rec[-3] rec[-11]\n",
      "    DETECTOR(4, 4, 0) rec[-2] rec[-10]\n",
      "    DETECTOR(4, 6, 0) rec[-1] rec[-9]\n",
      "}\n",
      "X_ERROR(0.01) 1 3 5 8 10 12 15 17 19\n",
      "M 1 3 5 8 10 12 15 17 19\n",
      "DETECTOR(0, 4, 1) rec[-3] rec[-6] rec[-13]\n",
      "DETECTOR(2, 2, 1) rec[-5] rec[-6] rec[-8] rec[-9] rec[-16]\n",
      "DETECTOR(4, 4, 1) rec[-1] rec[-2] rec[-4] rec[-5] rec[-11]\n",
      "DETECTOR(6, 2, 1) rec[-4] rec[-7] rec[-14]\n",
      "OBSERVABLE_INCLUDE(0) rec[-7] rec[-8] rec[-9]\n"
     ]
    }
   ],
   "source": [
    "print(kernel_circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [0 1 1 0]\n",
      " [0 1 1 0]\n",
      " ...\n",
      " [1 1 0 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def split_measurements(measurements, d):\n",
    "  n_measurements = idx_t(measurements.shape[1])\n",
    "  # Measurements on data qubits come last\n",
    "  exclude_indices = np.array([-x-1 for x in range(d**2)], dtype=idx_t)\n",
    "  exclude_indices = exclude_indices + n_measurements\n",
    "  # Out of all measurements on data qubits, the logical qubit measurements are those on the boundary of the lattice.\n",
    "  # All other equivalent X_L/Z_L operators can be found through the combination of ancilla measurements and the chosen data qubits giving us the logical qubit.\n",
    "  exclude_indices_obsL = np.array([-x-1 for x in range(d*(d-1), d**2)], dtype=idx_t)\n",
    "  exclude_indices_obsL = exclude_indices_obsL + n_measurements\n",
    "  # From obs_bits, we want to exclude all measurements except those listed in exclude_indices_obsL\n",
    "  exclude_indices_obs = np.arange(0, n_measurements, 1, dtype=idx_t)\n",
    "  exclude_indices_obs = np.delete(exclude_indices_obs, exclude_indices_obsL)\n",
    "\n",
    "  det_bits = measurements\n",
    "  det_bits = np.delete(det_bits, exclude_indices, axis=1)\n",
    "  obs_bits = measurements\n",
    "  obs_bits = np.delete(obs_bits, exclude_indices_obs, axis=1)\n",
    "\n",
    "  data_bits = measurements[:, exclude_indices]\n",
    "\n",
    "  # Reverse the order of data_bits because exclude_indices starts from the last data qubit measurement, not the first\n",
    "  data_bits = np.flip(data_bits, axis=1)\n",
    "\n",
    "  return det_bits, obs_bits, data_bits\n",
    "\n",
    "\n",
    "n_measurements = idx_t(measurements.shape[1])\n",
    "det_bits, obs_bits, data_bits = split_measurements(measurements, d)\n",
    "print(obs_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20000000, 16)\n",
      "(4, 20000000, 9)\n",
      "(4, 20000000, 3)\n",
      "(2, 20000000, 2)\n",
      "[1]\n",
      "[1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1]\n",
      "[0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0]\n",
      "[[[1, 1], [0, 1, 2, 3]]]\n",
      "[1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1]\n",
      "[0 1 0 1 0 0 1 0 0]\n",
      "[0 1 0]\n",
      "[0 0]\n",
      "[1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1]\n",
      "[0 0 1 1 0 0 1 0 0]\n",
      "[1 0 0]\n",
      "[0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0]\n",
      "[0 1 1 1 0 0 1 0 0]\n",
      "[1 1 0]\n",
      "[1 1]\n",
      "[0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[0 1 1 1 0 0 1 0 0]\n",
      "[1 1 0]\n",
      "(4, 20000000, 16)\n",
      "(4, 20000000, 1)\n"
     ]
    }
   ],
   "source": [
    "det_bits_kxk_all, data_bits_kxk_all, obs_bits_kxk_all, kernel_result_translation_map = call_group_det_bits_kxk(det_bits, data_bits_dxd=data_bits)\n",
    "print(det_bits_kxk_all.shape)\n",
    "print(data_bits_kxk_all.shape)\n",
    "print(obs_bits_kxk_all.shape)\n",
    "print(kernel_result_translation_map.shape)\n",
    "\n",
    "print(flips[0])\n",
    "print(det_bits[0])\n",
    "print(data_bits[0])\n",
    "\n",
    "kernel_types = get_unique_kernel_types(kernel_size, d)\n",
    "print(kernel_types)\n",
    "n_kernels = det_bits_kxk_all.shape[0]\n",
    "n_kernel_rows = int(np.sqrt(n_kernels))\n",
    "for k in range(n_kernels):\n",
    "  print(det_bits_kxk_all[k][0])\n",
    "  print(data_bits_kxk_all[k][0])\n",
    "  print(obs_bits_kxk_all[k][0])\n",
    "  if k % n_kernel_rows == 0:\n",
    "    print(kernel_result_translation_map[k//n_kernel_rows][0])\n",
    "\n",
    "det_evts_kxk_all = []\n",
    "flips_kxk_all = []\n",
    "for k in range(n_kernels):\n",
    "  measurements_kxk = np.concatenate((det_bits_kxk_all[k], data_bits_kxk_all[k]), axis=1).astype(np.bool_)\n",
    "  det_evts_kxk, flips_kxk = converter_kernel.convert(measurements=measurements_kxk, separate_observables=True, bit_packed=False)\n",
    "  det_evts_kxk_all.append(det_evts_kxk)\n",
    "  flips_kxk_all.append(flips_kxk)\n",
    "det_evts_kxk_all = np.array(det_evts_kxk_all, dtype=binary_t)\n",
    "flips_kxk_all = np.array(flips_kxk_all, dtype=binary_t)\n",
    "print(det_evts_kxk_all.shape)\n",
    "print(flips_kxk_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000000, 4, 16)\n",
      "(20000000, 4, 16)\n",
      "(20000000, 2)\n",
      "(20000000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Make sure the data type is np.int32 below, not idx_t!\n",
    "idxs_test, idxs_train = split_data(np.arange(n_samples, dtype=np.int32), test_size = n_test/n_samples, seed = 12345, shuffle = False)\n",
    "\n",
    "class_bits = flips\n",
    "features_det_bits = np.swapaxes(det_bits_kxk_all, 0, 1)\n",
    "features_det_evts = np.swapaxes(det_evts_kxk_all, 0, 1)\n",
    "features_translation_map = np.swapaxes(kernel_result_translation_map, 0, 1)[:,:,0]\n",
    "features_final_det_evts = det_evts[:, -((d**2-1)//2):]\n",
    "\n",
    "print(features_det_bits.shape)\n",
    "print(features_det_evts.shape)\n",
    "print(features_translation_map.shape)\n",
    "print(features_final_det_evts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNKernel(Layer):\n",
    "  def __init__(\n",
    "      self,\n",
    "      kernel_type, kernel_distance, rounds,\n",
    "      npol=1,\n",
    "      do_all_data_qubits = False,\n",
    "      include_det_evts = True,\n",
    "      n_remove_last_det_evts = 0,\n",
    "      **kwargs\n",
    "    ):\n",
    "    super(CNNKernel, self).__init__(**kwargs)\n",
    "    self.kernel_distance = kernel_distance\n",
    "    self.rounds = rounds\n",
    "    self.npol = npol\n",
    "    self.do_all_data_qubits = do_all_data_qubits\n",
    "    self.include_det_evts = include_det_evts\n",
    "    self.n_remove_last_det_evts = n_remove_last_det_evts\n",
    "    self.n_ancillas = (self.kernel_distance**2-1)\n",
    "\n",
    "    constraint_label = f\"{kernel_type[0]}_{kernel_type[1]}\"\n",
    "    num_outputs = 1\n",
    "    if self.do_all_data_qubits:\n",
    "      num_outputs = self.kernel_distance**2\n",
    "\n",
    "    ndim1 = self.n_ancillas*rounds # Number of ancilla measurements\n",
    "    if include_det_evts:\n",
    "      ndim1 += self.n_ancillas//2 + self.n_ancillas*(rounds-1) # Number of detector event bits within each round\n",
    "      ndim1 += self.n_ancillas//2 - self.n_remove_last_det_evts\n",
    "\n",
    "    self.ndims = []\n",
    "    for _ in range(self.npol):\n",
    "      self.ndims.append(ndim1)\n",
    "    self.ndims.append(num_outputs)\n",
    "\n",
    "    self.kernel_weights = self.add_weight(\n",
    "      name=f\"CNNkernel{self.kernel_distance}_{constraint_label}_w\",\n",
    "      shape=self.ndims,\n",
    "      initializer='zeros',\n",
    "      trainable=True\n",
    "    )\n",
    "    self.kernel_bias = self.add_weight(\n",
    "      name=f\"CNNkernel{self.kernel_distance}_{constraint_label}_b\",\n",
    "      shape=[num_outputs],\n",
    "      initializer='zeros',\n",
    "      trainable=True\n",
    "    )\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    pass\n",
    "\n",
    "  def call(self, inputs):\n",
    "    w = self.kernel_weights\n",
    "    x = tf.cast(inputs, tf.float32)\n",
    "    for _ in range(self.npol-1):\n",
    "      w = tf.matmul(x, w)\n",
    "    return tf.matmul(x, w) + self.kernel_bias\n",
    "  \n",
    "\n",
    "class FullCNNModel(Model):\n",
    "  def __init__(\n",
    "      self,\n",
    "      obs_type, code_distance, kernel_distance, rounds,\n",
    "      npol = 1,\n",
    "      do_all_data_qubits = False,\n",
    "      extended_kernel_output = True,\n",
    "      include_det_evts = True,\n",
    "      include_last_kernel_dets = False,\n",
    "      include_last_dets = True,\n",
    "      **kwargs\n",
    "    ):\n",
    "    super(FullCNNModel, self).__init__(**kwargs)\n",
    "    self.obs_type = obs_type\n",
    "    self.code_distance = code_distance\n",
    "    self.kernel_distance = kernel_distance\n",
    "    self.nshifts = self.code_distance - self.kernel_distance + 1\n",
    "    self.rounds = rounds\n",
    "    self.npol = npol\n",
    "    self.do_all_data_qubits = do_all_data_qubits\n",
    "    self.extended_kernel_output = extended_kernel_output\n",
    "    self.include_det_evts = include_det_evts\n",
    "    self.include_last_kernel_dets = include_last_kernel_dets\n",
    "    self.include_last_dets = include_last_dets\n",
    "\n",
    "    self.cnn_kernels = []\n",
    "    self.unique_kernel_types = get_unique_kernel_types(self.kernel_distance, code_distance)\n",
    "    for kernel_type in self.unique_kernel_types:\n",
    "      n_remove_last_dets = 0\n",
    "      kernel_parity = kernel_type[0]\n",
    "      if self.include_det_evts:\n",
    "        if self.include_last_kernel_dets:\n",
    "          if self.obs_type==\"ZL\":\n",
    "            if kernel_parity[0]==0:\n",
    "              n_remove_last_dets = 2\n",
    "            elif kernel_parity[0]==1 and self.code_distance>self.kernel_distance:\n",
    "              n_remove_last_dets = 1\n",
    "            elif kernel_parity[0]==-1:\n",
    "              n_remove_last_dets = 1\n",
    "          elif self.obs_type==\"XL\":\n",
    "            if kernel_parity[1]==0:\n",
    "              n_remove_last_dets = 2\n",
    "            elif kernel_parity[1]==1 and self.code_distance>self.kernel_distance:\n",
    "              n_remove_last_dets = 1\n",
    "            elif kernel_parity[1]==-1:\n",
    "              n_remove_last_dets = 1\n",
    "        else:\n",
    "          n_remove_last_dets = (self.kernel_distance**2-1)//2\n",
    "\n",
    "      self.cnn_kernels.append(\n",
    "        CNNKernel(\n",
    "          kernel_parity,\n",
    "          self.kernel_distance,\n",
    "          self.rounds,\n",
    "          self.npol,\n",
    "          self.do_all_data_qubits or self.extended_kernel_output,\n",
    "          self.include_det_evts,\n",
    "          n_remove_last_dets\n",
    "        )\n",
    "      )\n",
    "    \n",
    "    self.hidden_layers = [\n",
    "      Dense(100),\n",
    "      tf.keras.layers.Activation('relu'),\n",
    "      Dense(100),\n",
    "      tf.keras.layers.Activation('relu'),\n",
    "    ]\n",
    "\n",
    "    self.predictors = [\n",
    "      Dense(1 if not self.do_all_data_qubits else self.code_distance**2),\n",
    "      tf.keras.layers.Activation('sigmoid')\n",
    "    ]\n",
    "\n",
    "  def call(self, all_inputs):\n",
    "    det_bits = all_inputs[0]\n",
    "    det_evts = all_inputs[1]\n",
    "    translation_coefs = all_inputs[2]\n",
    "    final_det_evts = all_inputs[3]\n",
    "    predictor_inputs = []\n",
    "    for i, cnn_kernel in enumerate(self.cnn_kernels):\n",
    "      kernel_parity = self.unique_kernel_types[i][0]\n",
    "      kernel_idxs = self.unique_kernel_types[i][1]\n",
    "      for k in kernel_idxs:\n",
    "        kernel_input = None\n",
    "        det_bits_kernel = det_bits[:,k]\n",
    "        if self.include_det_evts:\n",
    "          det_evts_kernel = det_evts[:,k,0:-((self.kernel_distance**2-1)//2)]\n",
    "          if self.include_last_kernel_dets:\n",
    "            det_evts_kernel_end = det_evts[:,k,-((self.kernel_distance**2-1)//2):]\n",
    "            if self.obs_type==\"ZL\":\n",
    "              if kernel_parity[0]==0:\n",
    "                det_evts_kernel_end = det_evts_kernel_end[:,1:-1]\n",
    "              elif kernel_parity[0]==1 and self.code_distance>self.kernel_distance:\n",
    "                det_evts_kernel_end = det_evts_kernel_end[:,:-1]\n",
    "              elif kernel_parity[0]==-1:\n",
    "                det_evts_kernel_end = det_evts_kernel_end[:,1:]\n",
    "            elif self.obs_type==\"XL\":\n",
    "              if kernel_parity[1]==0:\n",
    "                det_evts_kernel_end = det_evts_kernel_end[:,1:-1]\n",
    "              elif kernel_parity[1]==1 and self.code_distance>self.kernel_distance:\n",
    "                det_evts_kernel_end = det_evts_kernel_end[:,:-1]\n",
    "              elif kernel_parity[1]==-1:\n",
    "                det_evts_kernel_end = det_evts_kernel_end[:,1:]\n",
    "            det_evts_kernel = tf.concat([det_evts_kernel, det_evts_kernel_end], axis=1)\n",
    "          kernel_input = tf.concat([det_bits_kernel, det_evts_kernel], axis=1)\n",
    "        else:\n",
    "          kernel_input = det_bits_kernel\n",
    "        kernel_output = cnn_kernel(kernel_input)\n",
    "        predictor_inputs.append(kernel_output)\n",
    "    predictor_inputs.append(tf.cast(translation_coefs, tf.float32))\n",
    "    if self.include_det_evts and self.include_last_dets:\n",
    "      predictor_inputs.append(tf.cast(final_det_evts, tf.float32))\n",
    "    predictor_inputs = tf.concat(predictor_inputs, axis=1)\n",
    "    x = predictor_inputs\n",
    "    for ll in self.hidden_layers:\n",
    "      x = ll(x)\n",
    "    for ll in self.predictors:\n",
    "      x = ll(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (1): Do not use the consistency detector event checks of the kernel (`include_last_kernel_dets=False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"full_cnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cnn_kernel (CNNKernel)      multiple                  261       \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  4600      \n",
      "                                                                 \n",
      " activation (Activation)     multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  10100     \n",
      "                                                                 \n",
      " activation_1 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  101       \n",
      "                                                                 \n",
      " activation_2 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15062 (58.84 KB)\n",
      "Trainable params: 15062 (58.84 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ulasc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "800/800 [==============================] - 32s 32ms/step - loss: 0.2013 - accuracy: 0.9148 - val_loss: 0.1195 - val_accuracy: 0.9506\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.1140 - accuracy: 0.9528 - val_loss: 0.1098 - val_accuracy: 0.9549\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 36s 45ms/step - loss: 0.1084 - accuracy: 0.9553 - val_loss: 0.1070 - val_accuracy: 0.9557\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.1059 - accuracy: 0.9564 - val_loss: 0.1047 - val_accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.1045 - accuracy: 0.9569 - val_loss: 0.1033 - val_accuracy: 0.9575\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 29s 37ms/step - loss: 0.1034 - accuracy: 0.9573 - val_loss: 0.1025 - val_accuracy: 0.9575\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.1027 - accuracy: 0.9576 - val_loss: 0.1019 - val_accuracy: 0.9578\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.1022 - accuracy: 0.9578 - val_loss: 0.1013 - val_accuracy: 0.9583\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.1017 - accuracy: 0.9580 - val_loss: 0.1015 - val_accuracy: 0.9580\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.1013 - accuracy: 0.9582 - val_loss: 0.1007 - val_accuracy: 0.9584\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.1009 - accuracy: 0.9584 - val_loss: 0.1004 - val_accuracy: 0.9586\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.1005 - accuracy: 0.9585 - val_loss: 0.1003 - val_accuracy: 0.9586\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.1003 - accuracy: 0.9586 - val_loss: 0.1002 - val_accuracy: 0.9586\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.1000 - accuracy: 0.9588 - val_loss: 0.1003 - val_accuracy: 0.9586\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.0998 - accuracy: 0.9588 - val_loss: 0.0995 - val_accuracy: 0.9589\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.0996 - accuracy: 0.9590 - val_loss: 0.0995 - val_accuracy: 0.9590\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 21s 27ms/step - loss: 0.0994 - accuracy: 0.9590 - val_loss: 0.0998 - val_accuracy: 0.9588\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.0993 - accuracy: 0.9590 - val_loss: 0.0994 - val_accuracy: 0.9590\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.0990 - accuracy: 0.9591 - val_loss: 0.0993 - val_accuracy: 0.9590\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 29s 36ms/step - loss: 0.0990 - accuracy: 0.9592 - val_loss: 0.0991 - val_accuracy: 0.9590\n"
     ]
    }
   ],
   "source": [
    "model_dxd = FullCNNModel(observable_type, d, kernel_size, r, do_all_data_qubits=False, extended_kernel_output=True, include_det_evts=True, include_last_kernel_dets=False, include_last_dets=True)\n",
    "model_dxd.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_dxd([features_det_bits[0:1], features_det_evts[0:1], features_translation_map[0:1], features_final_det_evts[0:1]])\n",
    "model_dxd.summary()\n",
    "\n",
    "val_split = 0.2\n",
    "n_epochs = 20\n",
    "history = model_dxd.fit(\n",
    "  x=[features_det_bits[idxs_train], features_det_evts[idxs_train], features_translation_map[idxs_train], features_final_det_evts[idxs_train]],\n",
    "  y=class_bits[idxs_train,:],\n",
    "  batch_size=10000,\n",
    "  epochs=n_epochs, validation_split=val_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 20s 18ms/step\n",
      "Inaccuracy of the final model (1) on the test data: 0.040981\n"
     ]
    }
   ],
   "source": [
    "flips_pred = model_dxd.predict([features_det_bits[idxs_test], features_det_evts[idxs_test], features_translation_map[idxs_test], features_final_det_evts[idxs_test]], batch_size=10000)\n",
    "print(f\"Inaccuracy of the final model (1) on the test data: {(flips[idxs_test]!=(flips_pred>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMatching error rate for test data set of the full dxd code: 0.0437033\n"
     ]
    }
   ],
   "source": [
    "pymatcher = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "flips_pred_pym = pymatcher.decode_batch(det_evts[idxs_test,:], bit_packed_predictions=False, bit_packed_shots=False).astype(binary_t).reshape(-1,1)\n",
    "print(f\"PyMatching error rate for test data set of the full dxd code: {np.sum((flips_pred_pym!=flips[idxs_test,:]))/idxs_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (2): Use the final consistency detector event checks of the kernel (`include_last_kernel_dets=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_cnn_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cnn_kernel_1 (CNNKernel)    multiple                  288       \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  4600      \n",
      "                                                                 \n",
      " activation_3 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  10100     \n",
      "                                                                 \n",
      " activation_4 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  101       \n",
      "                                                                 \n",
      " activation_5 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15089 (58.94 KB)\n",
      "Trainable params: 15089 (58.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 37s 41ms/step - loss: 0.2034 - accuracy: 0.9137 - val_loss: 0.1192 - val_accuracy: 0.9508\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 28s 35ms/step - loss: 0.1135 - accuracy: 0.9528 - val_loss: 0.1096 - val_accuracy: 0.9545\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 29s 36ms/step - loss: 0.1079 - accuracy: 0.9551 - val_loss: 0.1062 - val_accuracy: 0.9560\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 43s 54ms/step - loss: 0.1054 - accuracy: 0.9563 - val_loss: 0.1040 - val_accuracy: 0.9570\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 36s 45ms/step - loss: 0.1038 - accuracy: 0.9570 - val_loss: 0.1030 - val_accuracy: 0.9574\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 45s 56ms/step - loss: 0.1027 - accuracy: 0.9575 - val_loss: 0.1022 - val_accuracy: 0.9578\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 53s 66ms/step - loss: 0.1020 - accuracy: 0.9578 - val_loss: 0.1013 - val_accuracy: 0.9580\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 42s 52ms/step - loss: 0.1013 - accuracy: 0.9581 - val_loss: 0.1010 - val_accuracy: 0.9580\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 40s 50ms/step - loss: 0.1009 - accuracy: 0.9582 - val_loss: 0.1010 - val_accuracy: 0.9582\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 37s 47ms/step - loss: 0.1005 - accuracy: 0.9584 - val_loss: 0.1003 - val_accuracy: 0.9585\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 44s 55ms/step - loss: 0.1002 - accuracy: 0.9585 - val_loss: 0.1003 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 41s 51ms/step - loss: 0.0999 - accuracy: 0.9586 - val_loss: 0.1003 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 40s 50ms/step - loss: 0.0996 - accuracy: 0.9588 - val_loss: 0.0998 - val_accuracy: 0.9586\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 35s 44ms/step - loss: 0.0994 - accuracy: 0.9589 - val_loss: 0.0993 - val_accuracy: 0.9588\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 35s 44ms/step - loss: 0.0992 - accuracy: 0.9589 - val_loss: 0.0991 - val_accuracy: 0.9590\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 41s 51ms/step - loss: 0.0990 - accuracy: 0.9591 - val_loss: 0.0989 - val_accuracy: 0.9590\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 41s 51ms/step - loss: 0.0989 - accuracy: 0.9591 - val_loss: 0.0990 - val_accuracy: 0.9590\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 35s 44ms/step - loss: 0.0988 - accuracy: 0.9592 - val_loss: 0.0986 - val_accuracy: 0.9592\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 34s 43ms/step - loss: 0.0986 - accuracy: 0.9592 - val_loss: 0.0985 - val_accuracy: 0.9592\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.0985 - accuracy: 0.9592 - val_loss: 0.0990 - val_accuracy: 0.9589\n"
     ]
    }
   ],
   "source": [
    "model_dxd_wpde = FullCNNModel(observable_type, d, kernel_size, r, do_all_data_qubits=False, extended_kernel_output=True, include_det_evts=True, include_last_kernel_dets=True, include_last_dets=True)\n",
    "model_dxd_wpde.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_dxd_wpde([features_det_bits[0:1], features_det_evts[0:1], features_translation_map[0:1], features_final_det_evts[0:1]])\n",
    "model_dxd_wpde.summary()\n",
    "\n",
    "val_split = 0.2\n",
    "n_epochs = 20\n",
    "history = model_dxd_wpde.fit(\n",
    "  x=[features_det_bits[idxs_train], features_det_evts[idxs_train], features_translation_map[idxs_train], features_final_det_evts[idxs_train]],\n",
    "  y=class_bits[idxs_train,:],\n",
    "  batch_size=10000,\n",
    "  epochs=n_epochs, validation_split=val_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 18s 16ms/step\n",
      "Inaccuracy of the final model (2) on the test data: 0.0411954\n"
     ]
    }
   ],
   "source": [
    "flips_pred_wpde = model_dxd_wpde.predict([features_det_bits[idxs_test], features_det_evts[idxs_test], features_translation_map[idxs_test], features_final_det_evts[idxs_test]], batch_size=10000)\n",
    "print(f\"Inaccuracy of the final model (2) on the test data: {(flips[idxs_test]!=(flips_pred_wpde>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disagreement rate between models (1) and (2) on the test data: 0.014947\n",
      "Inaccuracy of models (1):(2) for the case where model (1) is more confident than model (2): 0.03575256208584472:0.03488857714052536 (56.41302% of the cases)\n",
      "Inaccuracy of models (1):(2) for the case where model (2) is more confident than model (1): 0.04774902594914608:0.04935917525848885 (43.58602% of the cases)\n",
      "Inaccuracy of models (1):(2) for the case where both models are equally confident: 0.0:0.0 (0.0009599999999999999% of the cases)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Disagreement rate between models (1) and (2) on the test data: {((flips_pred>0.5)!=(flips_pred_wpde>0.5)).astype(binary_t).sum()/idxs_test.shape[0]}\")\n",
    "\n",
    "# Case with flips_pred>flips_pred_wpde\n",
    "idxs_1gt2 = np.where(flips_pred>flips_pred_wpde)[0]\n",
    "# Case with flips_pred<flips_pred_wpde\n",
    "idxs_1lt2 = np.where(flips_pred<flips_pred_wpde)[0]\n",
    "# Case with flips_pred==flips_pred_wpde\n",
    "idxs_1eq2 = np.where(flips_pred==flips_pred_wpde)[0]\n",
    "\n",
    "print(f\"Inaccuracy of models (1):(2) for the case where model (1) is more confident than model (2): {(flips[idxs_test[idxs_1gt2]]!=(flips_pred[idxs_1gt2]>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_1gt2.shape[0]}:{(flips[idxs_test[idxs_1gt2]]!=(flips_pred_wpde[idxs_1gt2]>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_1gt2.shape[0]} ({idxs_1gt2.shape[0]/idxs_test.shape[0]*100.}% of the cases)\")\n",
    "print(f\"Inaccuracy of models (1):(2) for the case where model (2) is more confident than model (1): {(flips[idxs_test[idxs_1lt2]]!=(flips_pred[idxs_1lt2]>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_1lt2.shape[0]}:{(flips[idxs_test[idxs_1lt2]]!=(flips_pred_wpde[idxs_1lt2]>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_1lt2.shape[0]} ({idxs_1lt2.shape[0]/idxs_test.shape[0]*100.}% of the cases)\")\n",
    "print(f\"Inaccuracy of models (1):(2) for the case where both models are equally confident: {(flips[idxs_test[idxs_1eq2]]!=(flips_pred[idxs_1eq2]>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_1eq2.shape[0]}:{(flips[idxs_test[idxs_1eq2]]!=(flips_pred_wpde[idxs_1eq2]>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_1eq2.shape[0]} ({idxs_1eq2.shape[0]/idxs_test.shape[0]*100.}% of the cases)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: What if the kernel predicted a single bit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_cnn_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cnn_kernel_2 (CNNKernel)    multiple                  29        \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  1400      \n",
      "                                                                 \n",
      " activation_6 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  10100     \n",
      "                                                                 \n",
      " activation_7 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  101       \n",
      "                                                                 \n",
      " activation_8 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11630 (45.43 KB)\n",
      "Trainable params: 11630 (45.43 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 29s 31ms/step - loss: 0.2518 - accuracy: 0.8955 - val_loss: 0.1563 - val_accuracy: 0.9352\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 29s 36ms/step - loss: 0.1450 - accuracy: 0.9396 - val_loss: 0.1378 - val_accuracy: 0.9424\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.1358 - accuracy: 0.9433 - val_loss: 0.1335 - val_accuracy: 0.9444\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 26s 33ms/step - loss: 0.1327 - accuracy: 0.9448 - val_loss: 0.1312 - val_accuracy: 0.9461\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.1309 - accuracy: 0.9457 - val_loss: 0.1301 - val_accuracy: 0.9460\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.1297 - accuracy: 0.9464 - val_loss: 0.1295 - val_accuracy: 0.9457\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.1289 - accuracy: 0.9469 - val_loss: 0.1282 - val_accuracy: 0.9473\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.1281 - accuracy: 0.9473 - val_loss: 0.1275 - val_accuracy: 0.9474\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 25s 32ms/step - loss: 0.1275 - accuracy: 0.9477 - val_loss: 0.1268 - val_accuracy: 0.9484\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.1269 - accuracy: 0.9479 - val_loss: 0.1263 - val_accuracy: 0.9483\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 24s 30ms/step - loss: 0.1263 - accuracy: 0.9481 - val_loss: 0.1267 - val_accuracy: 0.9477\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 25s 31ms/step - loss: 0.1258 - accuracy: 0.9483 - val_loss: 0.1253 - val_accuracy: 0.9486\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 23s 29ms/step - loss: 0.1253 - accuracy: 0.9485 - val_loss: 0.1248 - val_accuracy: 0.9488\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.1249 - accuracy: 0.9486 - val_loss: 0.1246 - val_accuracy: 0.9488\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 26s 33ms/step - loss: 0.1245 - accuracy: 0.9487 - val_loss: 0.1244 - val_accuracy: 0.9488\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 24s 29ms/step - loss: 0.1242 - accuracy: 0.9488 - val_loss: 0.1237 - val_accuracy: 0.9492\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 26s 32ms/step - loss: 0.1238 - accuracy: 0.9490 - val_loss: 0.1234 - val_accuracy: 0.9492\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 25s 32ms/step - loss: 0.1235 - accuracy: 0.9491 - val_loss: 0.1228 - val_accuracy: 0.9497\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 26s 33ms/step - loss: 0.1232 - accuracy: 0.9492 - val_loss: 0.1229 - val_accuracy: 0.9496\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.1228 - accuracy: 0.9494 - val_loss: 0.1224 - val_accuracy: 0.9497\n"
     ]
    }
   ],
   "source": [
    "model_dxd_ksbit = FullCNNModel(observable_type, d, kernel_size, r, do_all_data_qubits=False, extended_kernel_output=False, include_det_evts=True, include_last_kernel_dets=False, include_last_dets=True)\n",
    "model_dxd_ksbit.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_dxd_ksbit([features_det_bits[0:1], features_det_evts[0:1], features_translation_map[0:1], features_final_det_evts[0:1]])\n",
    "model_dxd_ksbit.summary()\n",
    "\n",
    "val_split = 0.2\n",
    "n_epochs = 20\n",
    "history = model_dxd_ksbit.fit(\n",
    "  x=[features_det_bits[idxs_train], features_det_evts[idxs_train], features_translation_map[idxs_train], features_final_det_evts[idxs_train]],\n",
    "  y=class_bits[idxs_train,:],\n",
    "  batch_size=10000,\n",
    "  epochs=n_epochs, validation_split=val_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 13s 11ms/step\n",
      "Inaccuracy of the final model (3) on the test data: 0.0505507\n"
     ]
    }
   ],
   "source": [
    "flips_pred_ksbit = model_dxd_ksbit.predict([features_det_bits[idxs_test], features_det_evts[idxs_test], features_translation_map[idxs_test], features_final_det_evts[idxs_test]], batch_size=10000)\n",
    "print(f\"Inaccuracy of the final model (3) on the test data: {(flips[idxs_test]!=(flips_pred_ksbit>0.5).astype(binary_t)).astype(binary_t).sum()/idxs_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
